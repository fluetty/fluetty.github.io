<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>个人博客折腾记录</title>
      <link href="2020/11/13/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/"/>
      <url>2020/11/13/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>以前的博客都是记录在CSDN上的，最近在整理一些学习笔记，我想为什么不自己搭建个博客呢？那么说干就干吧。</p><p>我的想法是先利用现成的开源框架快速搭建一个博客，后期再折腾迭代（考虑手敲代码构建一个博客）。</p><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>现成有很多方案可以选择，我就选择了其中比较简单的 <a href="https://hexo.io/zh-cn">Hexo</a> 框架，使用的是<a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a> 主题。Hexo的基本常用指令没有几个，刚开始重点放在了主题的折腾上，逐渐会把重心向文章转移，专注于文章的写作。</p><h3 id="Hexo-GitHubPages-搭建博客"><a href="#Hexo-GitHubPages-搭建博客" class="headerlink" title="Hexo+GitHubPages 搭建博客"></a>Hexo+GitHubPages 搭建博客</h3><ol><li><p>Node.js下载安装</p></li><li><p>Git 下载安装</p></li><li><p>安装Hexo</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure></li></ol><ol start="4"><li><p>初始化 Hexo, 会新建一个文件夹   <a href="https://hexo.io/zh-cn/docs/">参考文档</a></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo init &lt;folder&gt;</span><br><span class="line">cd &lt;folder&gt;</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p>Hexo相关命令均在站点目录下用Git Bash运行。</p></li><li><p>启动服务器。在站点目录下（Git Bash)，执行以下命令，会实时监测文章的变更并渲染。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure></li><li><p>浏览器访问网址： <code>http://localhost:4000/</code> 此时Hexo博客已经运行在本地。默认的主题样式landscape在theme文件夹下。</p></li><li><p>新建文章，会在 站点目录/source/_posts 下生成一个 文章名字.md 文件，使用自己熟悉的markdown编辑器编辑保存文章，网页可实时查看效果。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo n &quot;文章名字&quot;</span><br></pre></td></tr></table></figure></li><li><p>GitHub：建立一个github.io的库 ，仓库名为：&lt;GitHub账号名称&gt;.github.io  <a href="https://sspai.com/post/54608">参考链接</a></p></li><li><p>将本地Hexo博客推送到GithubPages</p><ul><li><p>安装hexo-deployer-git插件。在命令行（即Git Bash）运行以下命令即可 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></li><li><p>添加到 GitHub。 复制密钥文件内容（路径形如<code>C:\Users\Administrator\.ssh\id_rsa.pub</code>），粘贴到<a href="https://github.com/settings/keys">New SSH Key</a>即可。</p></li><li><p>测试是否添加成功。在命令行（即Git Bash）依次输入以下命令，返回“You’ve successfully authenticated”即成功</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></li><li><p>修改<code>_config.yml</code>（在站点目录下）。文件末尾修改为：仓库地址写ssh地址， <strong>branch需要注意最近改为main了</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Deployment</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Docs: https://hexo.io/docs/deployment.html</span></span></span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: git@github.com:&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure></li><li><p>推送到GithubPages。在命令行（即Git Bash）依次输入以下命令， 返回<code>INFO Deploy done: git</code>即成功推送：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></li><li><p>等待1分钟左右，浏览器访问网址： <code>https://&lt;Github账号名称&gt;.github.io</code></p></li></ul></li></ol><p>​                 至此，Hexo博客已经搭建在GithubPages, 域名为<code>https://&lt;Github账号名称&gt;.github.io</code></p><h3 id="主题修改"><a href="#主题修改" class="headerlink" title="主题修改"></a>主题修改</h3><p>选择自己所需要的主题，下载安装，按照说明文档选择自己想要的效果修改即可。<a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a> 主题</p><h2 id="PicGo-GitHub实现图床"><a href="#PicGo-GitHub实现图床" class="headerlink" title="PicGo+GitHub实现图床"></a>PicGo+GitHub实现图床</h2><p>博客中所需要的文件存放在图床上，方便迁移的随取随用。我是用<a href="https://blog.csdn.net/fluetty/article/details/109224904">PicGo+GitHub实现图床</a></p><p>因为公司有外网，所以渲染加载图片很快，自己实际测试发现会加载不出图片。目前的折中方案是使用了路过图床，准备过一阵自己搭建个人图床。</p><h2 id="ToDo-List"><a href="#ToDo-List" class="headerlink" title="ToDo List"></a>ToDo List</h2><ol><li>文章笔记搬运、标签分类时间整理</li><li>博客碎碎念模块实现方案</li><li>博客样式完善</li><li>网站分析统计、搜索引擎收录网站、CDN</li><li>个人域名备案</li><li>博客部署，友链申请</li><li>搭建个人文件服务器</li><li>搭建个人图床</li></ol>]]></content>
      
      
      <categories>
          
          <category> blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>推送代码到GitHub遇到的Connection timed out问题</title>
      <link href="2020/11/10/%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E9%81%87%E5%88%B0Connection%20timed%20out%E9%97%AE%E9%A2%98/"/>
      <url>2020/11/10/%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E9%81%87%E5%88%B0Connection%20timed%20out%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>最近在尝试使用Hexo和GitHub构建个人博客，本地将代码推送到GitHub是完全正常的。可是今天推送代码时候却推不上去。</p><p>报错信息：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh: connect to host github.com port 22: Connection timed out</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">Please make sure you have the correct access rights and the repository exists.</span><br></pre></td></tr></table></figure><p>从报错信息可以看出连接GitHub超时，因为公司是能直接连接外网的，而且速度还很快，于是没有考虑网络的问题。我第一反应是配置有问题，于是就开始google解决方法。</p><p>我找到的第一种方法是重新生成并配置GitHub公钥。删除后重新生成并配置完成之后，还是推送不上。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;邮箱地址&quot;</span><br></pre></td></tr></table></figure><p>此时我又找别的解决方案，看到了这篇文章。<a href="https://www.jianshu.com/p/9f2962a6a217">关于github报错connect to host github.com port 22: Connection timed out的解决</a></p><p>我也切换端口连接了一下，发现连接成功了。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ssh -T -p 443 git@ssh.github.com</span><br></pre></td></tr></table></figure><p>文章中的解决方案是：通过修改github连接方式，从之前设置的ssh方法转成https方法。可是我并不想修改。</p><p>这时候我才想到有可能是网络的问题，于是我用手机热点成功推送，至此问题解决。</p>]]></content>
      
      
      <categories>
          
          <category> blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux下安装JDK1.8</title>
      <link href="2020/11/09/Linux%E4%B8%8B%E5%AE%89%E8%A3%85JDK/"/>
      <url>2020/11/09/Linux%E4%B8%8B%E5%AE%89%E8%A3%85JDK/</url>
      
        <content type="html"><![CDATA[<h2 id="下载-jdk1-8"><a href="#下载-jdk1-8" class="headerlink" title="下载 jdk1.8"></a>下载 jdk1.8</h2>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot;  http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="解压移动目录"><a href="#解压移动目录" class="headerlink" title="解压移动目录"></a>解压移动目录</h2><ol><li><p>tar命令解压，生成jdk1.8.0_131目录</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf jdk-8u131-linux-x64.tar.gz</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li><p>mv重命名jdk1.8.0_131为jdk1.8</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv jdk1.8.0_131 jdk1.8</span><br></pre></td></tr></table></figure></li><li><p>将jdk1.8移动到/usr/local 目录下（目录随意，环境变量配置为jdk路径）</p>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv jdk1.8 /usr/local</span><br></pre></td></tr></table></figure></li></ol><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><ol><li><p>修改/etc/profile 文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi  &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p>打开后如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201111155706887.png" alt="image-20201111155706887"></p></li><li><p>按 i 进入INSERT模式，在文件最后配置环境变量。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.8</span><br><span class="line">export JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre</span><br><span class="line">export CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib:$CLASSPATH</span><br><span class="line">export JAVA_PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$&#123;JRE_HOME&#125;&#x2F;bin</span><br><span class="line">export PATH&#x3D;$PATH:$&#123;JAVA_PATH&#125;</span><br></pre></td></tr></table></figure></li><li><p>按ESC退出编辑模式， :wq 保存退出</p></li><li><p>使profile配置生效</p>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure></li></ol><h2 id="检测是否安装成功"><a href="#检测是否安装成功" class="headerlink" title="检测是否安装成功"></a>检测是否安装成功</h2><ol><li><p>输入常用的java 命令即可，如查看版本号</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li><li><p>查看命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -help</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 服务器 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>PicGo+GitHub实现免费图床</title>
      <link href="2020/11/04/PicGo-GitHub%E5%AE%9E%E7%8E%B0%E5%85%8D%E8%B4%B9%E5%9B%BE%E5%BA%8A/"/>
      <url>2020/11/04/PicGo-GitHub%E5%AE%9E%E7%8E%B0%E5%85%8D%E8%B4%B9%E5%9B%BE%E5%BA%8A/</url>
      
        <content type="html"><![CDATA[<p>为了方便自己学习和工作两台电脑.md文件中图片的同步，所以了解到PicGo和Github实现免费图床，特将操作过程记录下来。</p><h2 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h2><p>图床一般就是指存储图片的服务器。图床一般是指储存图片的服务器，有国内和国外之分。国外的图床由于有空间距离等因素决定访问速度很慢影响图片显示速度。国内也分为单线空间、多线空间和cdn加速三种。<a href="https://baike.baidu.com/item/%E5%9B%BE%E5%BA%8A/10721348?fr=aladdin">百度百科</a></p><p>简单来说上传图片后会得到图片的链接，这样就可以通过此链接来查看图片，方便迁移。</p><h2 id="PicGo"><a href="#PicGo" class="headerlink" title="PicGo"></a>PicGo</h2><p><a href="https://molunerfinn.com/PicGo/">PicGo</a> 是一款图片上传的工具, 支持SM.MS图床，微博图床，七牛图床，腾讯云COS，阿里云OSS，Imgur，又拍云，<code>GitHub</code>等图床。我选择的是集成<code>GitHub</code>。</p><p>可以使用此工具将本地的图片文件上传到<code>GitHub</code>个人仓库中，方便快捷，markdown中图片不用再使用本地图片链接。<strong>需要注意的是隐私性问题，GitHub中你公开的仓库别人是可以访问的，也就是你的图片别人是可以看到的。</strong></p><p>安装完成后主界面是这样的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022155435359.png" alt="image-20201022155435359"></p><h2 id="GitHUb新建仓库"><a href="#GitHUb新建仓库" class="headerlink" title="GitHUb新建仓库"></a>GitHUb新建仓库</h2><ol><li>注册GitHub账号，有账号则直接登录。点击右上角头像旁加号，新建仓库。</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022155606104.png" alt="image-20201022155606104"></p><p>2.设置仓库的名字，注意要设置成public</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022155657318.png" alt="image-20201022155657318"></p><h2 id="生成密钥"><a href="#生成密钥" class="headerlink" title="生成密钥"></a>生成密钥</h2><ol><li>点击右上角头像，选择settings</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022155910865.png" alt="image-20201022155910865"></p><p>2.选择左侧 Developer settings</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022160948997.png" alt="image-20201022160948997"></p><p>3.生成新的token,note随意填写。</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022161231153.png" alt="image-20201022161231153"></p><p>4.复制保存新生成的token串</p><h2 id="PicGo配置图床"><a href="#PicGo配置图床" class="headerlink" title="PicGo配置图床"></a>PicGo配置图床</h2><ol><li><p>配置时候需要注意，分支名现在为main,不再是mater了。</p></li><li><p>指定存储路径，会在仓库下建个同名的文件夹。</p></li><li><p>自定义域名的作用是在上传图片后成功后，<code>PicGo</code>会将“自定义域名+上传的图片名”生成的访问链接，放到剪切板上<a href="https://raw.githubusercontent.com/%E7%94%A8%E6%88%B7%E5%90%8D/%E4%BB%93%E5%BA%93%E5%90%8D/main%EF%BC%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9F%9F%E5%90%8D%E9%9C%80%E8%A6%81%E6%8C%89%E7%85%A7%E8%BF%99%E6%A0%B7%E5%8E%BB%E5%A1%AB%E5%86%99">https://raw.githubusercontent.com/用户名/仓库名/main，自定义域名需要按照这样去填写</a></p></li><li><p>通过上传区可以测试上传，成功后GitHub中会有新建的文件夹和图片，PicGo相册中可以看到上传的图片。</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022161414837.png" alt="image-20201022161414837"></p><h2 id="Typora集成PicGo"><a href="#Typora集成PicGo" class="headerlink" title="Typora集成PicGo"></a>Typora集成PicGo</h2><p><a href="https://typora.io/">Typora</a> 是一款支持实时预览的Markdown 文本编辑器。非常好用，界面设计也挺有高级感。</p><ol><li>左上角 文件– 偏好设置 按照如图配置。配置后测试验证图片上传即可</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20201022161854170.png" alt="image-20201022161854170"></p><ol start="2"><li>使用Typora编辑文件时，拖拽图片进来，截图后复制黏贴图片都可。使用快捷键 <strong>Ctrl + Shift + I</strong>，可以调出插入图片的功能。</li></ol>]]></content>
      
      
      <categories>
          
          <category> blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>开源API网关Kong笔记</title>
      <link href="2020/11/03/%E5%BC%80%E6%BA%90API%E7%BD%91%E5%85%B3Kong%E7%AC%94%E8%AE%B0/"/>
      <url>2020/11/03/%E5%BC%80%E6%BA%90API%E7%BD%91%E5%85%B3Kong%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是API网关？"><a href="#什么是API网关？" class="headerlink" title="什么是API网关？"></a>什么是API网关？</h2><p>API 网关并非一个新兴的概念，在十几年前就已经存在了，它的作用主要是作为流量的入口，统一的处理和业务相关的请求，让请求更加安全、快速和准确的得到处理。</p><p>它有以下传统的功能：</p><ol><li><p>反向代理和负载均衡，这和 Nginx 的定位和功能是一致的；</p></li><li><p>动态上游、动态 SSL 证书和动态限流限速等运行时的动态功能，这是开源版本 Nginx并不具备的功能；</p></li><li><p>上游的主动和被动健康检查，以及服务熔断；</p></li><li><p>在 API 网关的基础之上进行扩展，成为全生命周期的 API 管理平台。</p></li></ol><h2 id="Kong简介"><a href="#Kong简介" class="headerlink" title="Kong简介"></a>Kong简介</h2><p>Kong基于<strong>Nginx</strong>，利用了其稳定性和高效率。Kong是Mashape开源的高性能高可用API网关和API服务管理层。</p><p>Kong是一个在Nginx中运行的Lua应用程序，并且可以通过lua-nginx模块实现。Kong不是用这个模块编译Nginx，而是与OpenResty一起分发，OpenResty已经包含了lua-nginx-module。OpenResty不是Nginx的分支，而是一组扩展其功能的模块。Kong基于OpenResty，进行API管理，并提供了插件实现API的AOP。</p><p> 这为可插拔架构奠定了基础，可以在运行时启用和执行Lua脚本（称为“插件”）。 因此，我们认为Kong是微服务架构的典范：它的核心是<strong>实现数据库抽象，路由和插件管理</strong>。 插件可以存在于单独的代码库中，并且可以在几行代码中注入到请求生命周期的任何位置。</p><p>目前互联网后台架构一般是采用微服务，或者类似微服务的形式，应用的请求通常需要访问多个后台系统。如果让每一个后台系统都实现鉴权、限流、<a href="https://cloud.tencent.com/product/clb?from=10680">负载均衡</a>、审计等基础功能是不合适的，通用的做法是把这些功能抽离出来放到网关层。Kong是目前最流行的网关平台。</p><h2 id="Kong的基本架构"><a href="#Kong的基本架构" class="headerlink" title="Kong的基本架构"></a>Kong的基本架构</h2><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/view.png" alt="view"></p><h3 id="Kong-默认绑定4个端口"><a href="#Kong-默认绑定4个端口" class="headerlink" title="Kong 默认绑定4个端口"></a>Kong 默认绑定4个端口</h3><ul><li>:8000 用来接受用户的HTTP请求，并转发到后台系统</li><li>:8443 用来接受用户的HTTPS请求，并转发到后台系统</li><li>:8001 通过HTTP协议提供管理功能的API （Admin API）</li><li>:8444 通过HTTPS协议提供管理功能的API</li></ul><p>这些端口可以在**/etc/kong/kong.conf**中修改，当然我们可以把Admin API作为一个服务通过kong的网关暴露出去。</p><h3 id="Kong-主要有三个组件"><a href="#Kong-主要有三个组件" class="headerlink" title="Kong 主要有三个组件"></a>Kong 主要有三个组件</h3><ul><li>Kong Server ：基于nginx的服务器，用来接收 API 请求。</li><li>Apache Cassandra/PostgreSQL：用来存储操作数据。</li><li>Kong dashboard：官方推荐 UI 管理工具，当然，也可以使用 restfull 方式管理 admin api。</li></ul><p>Kong 采用插件机制进行功能定制，插件集（可以是 0 或 N 个）在 API 请求响应循环的生命周期中被执行。<strong>插件使用 Lua 编写</strong>，基础功能包括：HTTP 基本认证、密钥认证、CORS（Cross-Origin Resource Sharing，跨域资源共享）、TCP、UDP、文件日志、API 请求限流、请求转发以及 Nginx 监控等。</p><h3 id="Kong-网关具有以下的特性"><a href="#Kong-网关具有以下的特性" class="headerlink" title="Kong 网关具有以下的特性"></a>Kong 网关具有以下的特性</h3><ul><li>可扩展性: 通过简单地添加更多的服务器，可以轻松地进行横向扩展，这意味着您的平台可以在一个较低负载的情况下处理任何请求；</li><li>模块化: 可以通过添加新的插件进行扩展，这些插件可以通过RESTful Admin API轻松配置；</li><li>在任何基础架构上运行: Kong 网关可以在任何地方都能运行。可以在云或内部网络环境中部署 Kong，包括单个或多个数据中心设置，以及 public，private 或 invite-only APIs。</li></ul><h2 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h2><ul><li><p>Route：是请求的转发规则，按照Hostname和PATH，将请求转发给Service。<strong>路由是定义对这个服务暴露给客户端的请求路径及请求方式。服务与路由是1对多的关系，一个服务可以以多种路由方式暴露给前端访问，该服务对应的上游服务就是1个API</strong>。  告诉Kong怎么把网关收到的请求发送到某个特定的后台服务。</p></li><li><p>Services：是多个Upstream的集合，是Route的转发目标。<strong>不要把Services当作后端的具体API，要把它当作一个大的服务，该服务下面有多个API（endpoint or route）</strong>。</p></li><li><p>Consumer：是API的用户，里面记录用户的一些信息。</p></li><li><p>Plugin：是插件，plugin可以是全局的，绑定到Service，绑定到Router，绑定到Consumer。</p></li><li><p>Certificate：是https证书。</p></li><li><p>Sni：是域名与Certificate的绑定，指定了一个域名对应的https证书。</p></li><li><p>Upstream：表示虚拟主机名，可用于通过多个服务（目标）对传入请求进行负载均衡。例如：service.v1.xyz 为Service对象命名的上游host是service.v1.xyz对此服务的请求将代理到上游定义的目标。</p></li><li><p>Target：目标IP地址/主机名，其端口表示后端服务的实例,是最终处理请求的Backend服务。每个上游都可以有多个target,并且可以动态添加Target。 由于Upstream维护Target的更改历史记录，因此无法删除或者修改Target。要禁用目标，请发布一个新的Target weight=0,或者使用DELETE来完成相同的操作。</p></li></ul><h2 id="Kong插件的格式"><a href="#Kong插件的格式" class="headerlink" title="Kong插件的格式"></a>Kong插件的格式</h2><p>一个完整的插件目录结构应该像下面这样：</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/image-20200831151628965.png" alt="image-20200831151628965"></p><p>各个模块的功能：</p><table><thead><tr><th>模块名</th><th>描述</th><th>是否必需</th></tr></thead><tbody><tr><td>api.lua</td><td>插件需要向 Admin API 暴露接口时使用</td><td>N</td></tr><tr><td>daos.lua</td><td>数据层相关，当插件需要访问数据库时配置</td><td>N</td></tr><tr><td>handler.lua</td><td>插件的主要逻辑，这个将会被 Kong 在不同阶段执行其对应的 handler</td><td>Y</td></tr><tr><td>migrations / *.lua</td><td>插件依赖的数据表结构，启用了 daos.lua 时需要定义</td><td>N</td></tr><tr><td>schema.lua</td><td>插件的配置参数定义，主要用于 Kong 参数验证</td><td>Y</td></tr></tbody></table><p>其中 handler.lua 和 schema.lua 是必需的（rbac_charing下也是只有这两个），上面提到的插件需要暴露出来的方法就定义在 handler.lua 中。</p><p><strong>kong插件主要有三个文件</strong>：</p><p>handler.lua 是包含插件逻辑处理相关代码。 schema.lua 包含插件的配置文件。 rockspec 文件是通过luarock安装时用的配置文件。</p><p>逻辑处理的代码根据openResty的不同处理阶段分成了不同的函数，根据插件的功能只需要在不同的函数中添加自己的业务逻辑。</p><h2 id="跟路径（path）有关的参数"><a href="#跟路径（path）有关的参数" class="headerlink" title="跟路径（path）有关的参数"></a>跟路径（path）有关的参数</h2><ol><li> route中的paths参数，表示符合这些请求路径要发到route对应的service中</li><li> route中的strip_path 参数，决定kong转发给后端的时候是否保留源请求用于路由匹配的路径</li><li>service中的path参数，默认为null，kong转发请求时会把这个作为前缀加上</li></ol><p>假设网关以<code>/api</code>为路由把请求转发给nodedemo（即<code>route.paths = [&#39;/api&#39;]</code>)，它们的组合关系如下：</p><table><thead><tr><th>strip_path</th><th>service.path</th><th>请求地址</th><th>网关实际访问后端地址</th></tr></thead><tbody><tr><td>true</td><td>null 或者 /</td><td><a href="http://127.0.0.1/api/demo">http://127.0.0.1/api/demo</a></td><td><a href="http://127.0.0.1:8080/demo">http://127.0.0.1:8080/demo</a></td></tr><tr><td>true</td><td>/test</td><td><a href="http://127.0.0.1/api/demo">http://127.0.0.1/api/demo</a></td><td><a href="http://127.0.0.1:8080/test/demo">http://127.0.0.1:8080/test/demo</a></td></tr><tr><td>false</td><td>null 或者 /</td><td><a href="http://127.0.0.1/api/demo">http://127.0.0.1/api/demo</a></td><td><a href="http://127.0.0.1:8080/api/demo">http://127.0.0.1:8080/api/demo</a></td></tr><tr><td>false</td><td>/test</td><td><a href="http://127.0.0.1/api/demo">http://127.0.0.1/api/demo</a></td><td><a href="http://127.0.0.1:8080/test/api/demo">http://127.0.0.1:8080/test/api/demo</a></td></tr></tbody></table><p>以最后一行为例，相当于访问 <a href="http://127.0.0.1/api/demo">http://127.0.0.1/api/demo</a> 时，实际访问的是<code>/test/api/demo</code>，也就是把 service.path (/test）跟实际请求的路径(/api/demo)拼接起来发给后端。</p><p>配置route时候：这里的 Path 就是具体业务API的路径（endpoint）。Hosts不设置会默认采用Services里的Host，但是一旦设置了，客户端请求该route的时候必须带上设置的host，且必须一致。</p><p>如果Strip path设置为YES，这里的 Path 可以加一个前缀，如：/passport/users，但最终会映射到后端真实的API /users。Kong转发到后端服务的时候会把前缀/passport部分去掉。客户端调用API必须和Routes里的Path一致才行（/passport/users），否则会得到404，无法匹配。用户的请求是先匹配route，然后转发到service。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="http://blog.didispace.com/hzf-ms-apigateway-2/">微服务与API 网关（下）- Kong能为我们做什么？</a></p><p><a href="https://segmentfault.com/a/1190000019857235">企业级API网关Kong系列</a></p><p><a href="https://ms2008.github.io/2018/05/14/kong-plugin-load/">Kong 插件加载机制概述</a></p><p><a href="https://www.cnblogs.com/SummerinShire/p/6925308.html">Kong-负载均衡参考</a></p><p><a href="https://www.jianshu.com/p/b65259021d2b">Kong负载均衡的实现</a></p><p><a href="%5Bhttps://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2018/11/20/kong-features-16-work-process.html#%E4%BB%8E-upstream-%E5%88%B0-target%5D(https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2018/11/20/kong-features-16-work-process.html#%E4%BB%8E-upstream-%E5%88%B0-target)">upstream和target详解</a></p>]]></content>
      
      
      <categories>
          
          <category> study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> learn </tag>
            
            <tag> kong </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker常用指令</title>
      <link href="2020/11/02/Docker%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"/>
      <url>2020/11/02/Docker%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p><strong>简介：</strong>Docker 是一个开源的应用容器引擎，基于 Go 语言开发，Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的系统。</p><p>docker本质就是宿主机的一个进程，docker是通过namespace实现资源隔离，通过cgroup实现资源限制，通过写时复制技术（copy-on-write）实现了高效的文件操作（类似虚拟机的磁盘比如分配500g并不是实际占用物理磁盘500g）</p><h2 id="Docker-三个核心概念"><a href="#Docker-三个核心概念" class="headerlink" title="Docker 三个核心概念"></a>Docker 三个核心概念</h2><h3 id="镜像（Image）"><a href="#镜像（Image）" class="headerlink" title="镜像（Image）"></a>镜像（Image）</h3><p>是一个包含有文件系统的面向 Docker 引擎的只读模板。任何应用程序运行都需要环境，而镜像就是用来提供这种运行环境的。例如一个 Ubuntu 镜像就是一个包含 Ubuntu 操作系统环境的模板。Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。</p><h3 id="容器（Container）"><a href="#容器（Container）" class="headerlink" title="容器（Container）"></a>容器（Container）</h3><p>类似于一个轻量级的沙盒，可以将其看作一个极简的 Linux 系统环境（包括 root 权限、进程空间、用户空间和网络空间等），以及运行在其中的应用程序。Docker 引擎利用容器来运行、隔离各个应用。</p><p>容器是镜像创建的应用实例，可以创建、启动、停止、删除容器，各个容器之间是是相互隔离的，互不影响。</p><p>注意：镜像本身是只读的，容器从镜像启动时，Docker 在镜像的上层创建一个可写层，镜像本身不变。</p><h3 id="仓库（Repository）"><a href="#仓库（Repository）" class="headerlink" title="仓库（Repository）"></a>仓库（Repository）</h3><p>镜像仓库，是 Docker 用来集中存放镜像文件的地方。</p><h2 id="Docker常用命令"><a href="#Docker常用命令" class="headerlink" title="Docker常用命令"></a>Docker常用命令</h2><p>Docker 的常用命令一般分为：镜像管理、容器管理。</p><h3 id="查看-Docker-版本"><a href="#查看-Docker-版本" class="headerlink" title="查看 Docker 版本"></a>查看 Docker 版本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker version</span><br></pre></td></tr></table></figure><h3 id="列出常用命令"><a href="#列出常用命令" class="headerlink" title="列出常用命令"></a>列出常用命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker --help</span><br></pre></td></tr></table></figure><h3 id="镜像管理命令"><a href="#镜像管理命令" class="headerlink" title="镜像管理命令"></a>镜像管理命令</h3><p>下面使用 busybox 软件作为示例，busybox 软件是一个集成了非常多最常用的 Linux 命令和工具的软件集合。</p><h4 id="查看所有镜像"><a href="#查看所有镜像" class="headerlink" title="查看所有镜像"></a>查看所有镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker images</span><br><span class="line">docker images ls</span><br></pre></td></tr></table></figure><ul><li><p>REPOSITORY：镜像来自哪个仓库</p></li><li><p>TAG：镜像的标签信息，版本之类的信息</p></li><li><p>IMAGE ID：镜像创建时的id</p></li><li><p>CREATED：镜像创建的时间</p></li><li><p>SIZE：镜像文件大小</p></li></ul><h4 id="下载软件镜像"><a href="#下载软件镜像" class="headerlink" title="下载软件镜像"></a>下载软件镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull busybox:latest</span><br></pre></td></tr></table></figure><p>备注：latest 表示使用 busybox 软件的最新版本，所以软件默认下载都是 latest 版本。</p><h4 id="导出镜像"><a href="#导出镜像" class="headerlink" title="导出镜像"></a>导出镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker save busybox &gt; busybox.tar</span><br></pre></td></tr></table></figure><p>备注：把 busybox 镜像导出为 busybox.tar 文件，可以把 busybox.tar 文件复制到别的操作系统上使用，免除下载时网络慢的问题。</p><h4 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker rmi busybox:latest</span><br></pre></td></tr></table></figure><p>备注：镜像一般都会根据版本打包，如果有下载一个软件的多个版本就需要指定具体版本信息。如 busybox:1.26 就会删除 busybox 软件的 1.26 版本的镜像，不会删除latest 版本的镜像。</p><h4 id="导入镜像"><a href="#导入镜像" class="headerlink" title="导入镜像"></a>导入镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker load &lt; busybox.tar</span><br></pre></td></tr></table></figure><p>备注：使用导出命令导出的镜像，可以通过此命令导入到没有下载此软件的操作系统，方便网络条件差的情况使用。</p><h4 id="更改镜像名"><a href="#更改镜像名" class="headerlink" title="更改镜像名"></a>更改镜像名</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker tag busybox:latest busybox:test</span><br></pre></td></tr></table></figure><p>备注：busybox:latest原镜像名，busybox:test要改成的镜像名</p><h3 id="容器管理命令"><a href="#容器管理命令" class="headerlink" title="容器管理命令"></a><strong>容器管理命令</strong></h3><h4 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=busybox busybox:latest ping 114.114.114.114</span><br><span class="line">docker container run -p 8000:3000 -it demo:0.0.1 /bin/bash</span><br></pre></td></tr></table></figure><ul><li><code>run</code>：run参数代表启动容器</li><li><code>-d</code>：以后台daemon的方式运行</li><li><code>--name</code>：指定一个容器的名字，此后操作都需要使用这个名字来定位容器。</li><li><code>busybox:latest</code>：容器所使用的镜像名字</li><li><code>ping 114.114.114.114</code>：启动容器执行的命令</li></ul><h4 id="查看运行的容器"><a href="#查看运行的容器" class="headerlink" title="查看运行的容器"></a>查看运行的容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line">docker container ls</span><br></pre></td></tr></table></figure><h4 id="查看所有容器"><a href="#查看所有容器" class="headerlink" title="查看所有容器"></a>查看所有容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><ul><li><code>CONTAINER ID</code>：容器启动的id</li><li><code>IMAGE</code>：使用哪个镜像启动的容器</li><li><code>COMMAND</code>：启动容器的命令</li><li><code>CREATED</code>：创建容器的时间</li><li><code>STATUS</code>：容器启动时间</li><li><code>PORTS</code>：容器映射到宿主机的端口</li><li><code>NAMES</code>：容器启动的名字</li></ul><h4 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker start busybox</span><br></pre></td></tr></table></figure><h4 id="重新启动容器"><a href="#重新启动容器" class="headerlink" title="重新启动容器"></a>重新启动容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker restart busybox</span><br></pre></td></tr></table></figure><h4 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker stop busybox</span><br></pre></td></tr></table></figure><h4 id="杀死容器"><a href="#杀死容器" class="headerlink" title="杀死容器"></a>杀死容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker kill busybox</span><br></pre></td></tr></table></figure><h4 id="清理所有终止状态的容器"><a href="#清理所有终止状态的容器" class="headerlink" title="清理所有终止状态的容器"></a>清理所有终止状态的容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker container prune</span><br></pre></td></tr></table></figure><h4 id="列出容器映射的端口"><a href="#列出容器映射的端口" class="headerlink" title="列出容器映射的端口"></a>列出容器映射的端口</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker port busybox</span><br></pre></td></tr></table></figure><h4 id="查看容器内部运行的进程"><a href="#查看容器内部运行的进程" class="headerlink" title="查看容器内部运行的进程"></a>查看容器内部运行的进程</h4><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">docker top busybox</span><br></pre></td></tr></table></figure><h4 id="查看容器或镜像底层信息"><a href="#查看容器或镜像底层信息" class="headerlink" title="查看容器或镜像底层信息"></a>查看容器或镜像底层信息</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker inspect busybox</span><br></pre></td></tr></table></figure><h4 id="删除运行中的容器"><a href="#删除运行中的容器" class="headerlink" title="删除运行中的容器"></a>删除运行中的容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker rm -f busybox</span><br></pre></td></tr></table></figure><h4 id="执行容器内命令"><a href="#执行容器内命令" class="headerlink" title="执行容器内命令"></a>执行容器内命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it busybox ls</span><br><span class="line">docker exec -it busybox /bin/bash</span><br></pre></td></tr></table></figure><p>备注：-it 交互终端</p><h4 id="复制容器内文件"><a href="#复制容器内文件" class="headerlink" title="复制容器内文件"></a>复制容器内文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp busybox:/etc/hosts hosts</span><br></pre></td></tr></table></figure><h4 id="查看容器日志"><a href="#查看容器日志" class="headerlink" title="查看容器日志"></a>查看容器日志</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker logs -f busybox</span><br><span class="line">docker logs [OPTIONS] busybox</span><br></pre></td></tr></table></figure><p>OPTIONS说明：</p><ul><li><code>-f</code>：跟踪日志输出</li><li><code>--since</code>：显示某个开始时间的所有日志</li><li><code>-t</code>：显示时间戳</li><li><code>--tail</code>：仅列出最新N条容器日志</li></ul><h2 id="docker-compose"><a href="#docker-compose" class="headerlink" title="docker-compose"></a>docker-compose</h2><p>Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，可以使用 YML 文件来配置应用程序需要的所有服务。然后使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。  compose命令大多依赖于yml文件，默认使用当前目录下的“docker-compose.yml“，也可以通过－f指定。</p><h4 id="构建建启动nignx容器"><a href="#构建建启动nignx容器" class="headerlink" title="构建建启动nignx容器"></a>构建建启动nignx容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose up -d nginx          </span><br></pre></td></tr></table></figure><h4 id="进入到nginx容器中"><a href="#进入到nginx容器中" class="headerlink" title="进入到nginx容器中"></a>进入到nginx容器中</h4> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose exec nginx bash     </span><br></pre></td></tr></table></figure><h4 id="删除所有nginx容器-镜像"><a href="#删除所有nginx容器-镜像" class="headerlink" title="删除所有nginx容器,镜像"></a>删除所有nginx容器,镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose down         </span><br></pre></td></tr></table></figure><h4 id="重新启动nginx容器"><a href="#重新启动nginx容器" class="headerlink" title="重新启动nginx容器"></a>重新启动nginx容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose restart nginx</span><br></pre></td></tr></table></figure><h4 id="在php-fpm中不启动关联容器，并容器执行php-v-执行完成后删除容器"><a href="#在php-fpm中不启动关联容器，并容器执行php-v-执行完成后删除容器" class="headerlink" title="在php-fpm中不启动关联容器，并容器执行php -v 执行完成后删除容器"></a>在php-fpm中不启动关联容器，并容器执行php -v 执行完成后删除容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose run --no-deps --rm php-fpm php -v </span><br></pre></td></tr></table></figure><h4 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose build nginx  </span><br></pre></td></tr></table></figure><h4 id="不带缓存的构建"><a href="#不带缓存的构建" class="headerlink" title="不带缓存的构建"></a>不带缓存的构建</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose build --no-cache nginx </span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cnblogs.com/edisonchou/p/dockerfile_inside_introduction.html">你必须知道的Dockerfile</a></p><p><a href="https://www.cnblogs.com/moxiaoan/p/9299404.html">Docker-compose常用命令</a></p>]]></content>
      
      
      <categories>
          
          <category> study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx学习记录</title>
      <link href="2020/10/20/nginx%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
      <url>2020/10/20/nginx%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h2 id="Nginx-简介"><a href="#Nginx-简介" class="headerlink" title="Nginx 简介"></a>Nginx 简介</h2><p>Nginx是一款免费开源、轻量级的高性能 Web服务器、反向代理服务器，它高并发性能很好，官方测试能够支撑 5 万的并发量；运行时内存和 CPU 占用率低，配置简单，容易上手，而且运行非常稳定。由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。</p><p>Nginx是由俄罗斯人Igor Sysoev 设计开发的，第一次公开发布在2004年10月4日。 <a href="http://nginx.org/">官方网站</a></p><h2 id="Nginx的常用功能"><a href="#Nginx的常用功能" class="headerlink" title="Nginx的常用功能"></a>Nginx的常用功能</h2><p>Nginx的功能特别多，详见<a href="http://nginx.org/en/">官网介绍</a> ，比较常用的功能有以下几个。</p><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><p>这是 Nginx 服务器作为 WEB 服务器的主要功能之一，客户端向服务器发送请求时，会首先经过 Nginx 服务器，由服务器将请求分发到相应的 WEB 服务器。<strong>正向代理是代理客户端，而反向代理则是代理服务器</strong>，Nginx 在提供反向代理服务方面，通过使用正则表达式进行相关配置，采取不同的转发策略，配置相当灵活，而且在配置后端转发请求时，完全不用关心网络环境如何，可以指定任意的IP地址和端口号，或其他类型的连接、请求等。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>这也是 Nginx 最常用的功能之一，负载均衡，<strong>一方面是将单一的重负载分担到多个网络节点上做并行处理</strong>，每个节点处理结束后将结果汇总返回给用户，这样可以大幅度提高网络系统的处理能力；<strong>另一方面将大量的前端并发请求或数据流量分担到多个后端网络节点分别处理</strong>，这样可以有效减少前端用户等待相应的时间。而 Nginx 负载均衡都是属于后一方面，主要是<strong>对大量前端访问或流量进行分流</strong>，以保证前端用户访问效率，并可以减少后端服务器处理压力。</p><h3 id="Web缓存"><a href="#Web缓存" class="headerlink" title="Web缓存"></a>Web缓存</h3><p>缓存，是Nginx提供的，可以加快访问速度的机制，说白了，在配置上就是一个开启，同时指定目录，让缓存可以存储到磁盘上。在很多优秀的网站中，Nginx 可以作为前置缓存服务器，它被用于缓存前端请求，从而提高 Web服务器的性能。Nginx 会对用户已经访问过的内容在服务器本地建立副本，这样在一段时间内再次访问该数据，就不需要通过 Nginx 服务器向后端发出请求。减轻网络拥堵，减小数据传输延时，提高用户访问速度。</p><h2 id="Nginx的安装"><a href="#Nginx的安装" class="headerlink" title="Nginx的安装"></a>Nginx的安装</h2><p>​                参考：<a href="https://www.cnblogs.com/taiyonghai/p/6728707.html">Nginx Linux详细安装部署教程</a></p><p>​                          <a href="https://www.cnblogs.com/taiyonghai/p/9402734.html">Nginx Windows详细安装部署教程</a></p><h3 id="启动-Nginx"><a href="#启动-Nginx" class="headerlink" title="启动 Nginx"></a>启动 Nginx</h3><p>window在解压的nginx目录下 打开cmd.exe</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start nginx</span><br></pre></td></tr></table></figure><h3 id="查看服务是否启动"><a href="#查看服务是否启动" class="headerlink" title="查看服务是否启动"></a>查看服务是否启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -ef | grep nginx</span><br></pre></td></tr></table></figure><h3 id="重启Nginx"><a href="#重启Nginx" class="headerlink" title="重启Nginx"></a>重启Nginx</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h3 id="关闭Nginx"><a href="#关闭Nginx" class="headerlink" title="关闭Nginx"></a>关闭Nginx</h3><p>先查出nginx进程id再使用kill命令强制杀掉进程</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx -s stop</span><br></pre></td></tr></table></figure><p>允许 nginx 服务将当前正在处理的网络请求处理完成，但不再接收新的请求，之后关闭连接，停止工作。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx -s quit</span><br></pre></td></tr></table></figure><h3 id="检查配置文件语法"><a href="#检查配置文件语法" class="headerlink" title="检查配置文件语法"></a>检查配置文件语法</h3><p>指定要检查的文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx -t -c nginx/conf/nginx/conf</span><br></pre></td></tr></table></figure><p>默认检查nginx.conf配置文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><h2 id="Nginx-conf配置文件"><a href="#Nginx-conf配置文件" class="headerlink" title="Nginx.conf配置文件"></a>Nginx.conf配置文件</h2><ul><li>1、<strong>全局块</strong>：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。</li><li>2、<strong>events块</strong>：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。</li><li>3、<strong>http块</strong>：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。</li><li>4、<strong>server块</strong>：配置虚拟主机的相关参数，一个http中可以有多个server。</li><li>5、<strong>location块</strong>：配置请求的路由，以及各种页面的处理情况。</li></ul><p>nginx配置文件详解</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#user  nobody;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#==工作进程数，一般设置为cpu核心数</span></span><br><span class="line">worker_processes  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">#error_log  logs/error.log;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  notice;</span></span><br><span class="line"><span class="comment">#error_log  logs/error.log  info;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#pid        logs/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#==最大连接数，一般设置为cpu*2048</span></span><br><span class="line">    worker_connections  <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">    <span class="comment">#                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">    <span class="comment">#                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#access_log  logs/access.log  main;</span></span><br><span class="line">    </span><br><span class="line">    sendfile        on;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#keepalive_timeout  0;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#==客户端链接超时时间</span></span><br><span class="line">    keepalive_timeout  <span class="number">65</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#当配置多个server节点时，默认server names的缓存区大小就不够了，需要手动设置大一点</span></span><br><span class="line">    server_names_hash_bucket_size <span class="number">512</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#server表示虚拟主机可以理解为一个站点，可以配置多个server节点搭建多个站点</span></span><br><span class="line">    <span class="comment">#每一个请求进来确定使用哪个server由server_name确定</span></span><br><span class="line">    server &#123;</span><br><span class="line">        <span class="comment">#站点监听端口</span></span><br><span class="line">        listen       <span class="number">8800</span>;</span><br><span class="line">        <span class="comment">#站点访问域名</span></span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#编码格式，避免url参数乱码</span></span><br><span class="line">        charset utf<span class="number">-8</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">#access_log  logs/host.access.log  main;</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">#location用来匹配同一域名下多个URI的访问规则</span></span><br><span class="line">        <span class="comment">#比如动态资源如何跳转，静态资源如何跳转等</span></span><br><span class="line">        <span class="comment">#location后面跟着的/代表匹配规则</span></span><br><span class="line">        location / &#123;</span><br><span class="line">            <span class="comment">#站点根目录，可以是相对路径，也可以使绝对路径</span></span><br><span class="line">            root   html;</span><br><span class="line">            <span class="comment">#默认主页</span></span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#转发后端站点地址，一般用于做软负载，轮询后端服务器</span></span><br><span class="line">            <span class="comment">#proxy_pass http://10.11.12.237:8080;</span></span><br><span class="line">    </span><br><span class="line">            <span class="comment">#拒绝请求，返回403，一般用于某些目录禁止访问</span></span><br><span class="line">            <span class="comment">#deny all;</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#允许请求</span></span><br><span class="line">            <span class="comment">#allow all;</span></span><br><span class="line">            </span><br><span class="line">            add_header <span class="string">&#x27;Access-Control-Allow-Origin&#x27;</span> <span class="string">&#x27;*&#x27;</span>;</span><br><span class="line">            add_header <span class="string">&#x27;Access-Control-Allow-Credentials&#x27;</span> <span class="string">&#x27;true&#x27;</span>;</span><br><span class="line">            add_header <span class="string">&#x27;Access-Control-Allow-Methods&#x27;</span> <span class="string">&#x27;GET, POST, OPTIONS&#x27;</span>;</span><br><span class="line">            add_header <span class="string">&#x27;Access-Control-Allow-Headers&#x27;</span> <span class="string">&#x27;DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type&#x27;</span>;</span><br><span class="line">            <span class="comment">#重新定义或者添加发往后端服务器的请求头</span></span><br><span class="line">            <span class="comment">#给请求头中添加客户请求主机名</span></span><br><span class="line">            proxy_set_header Host $host;</span><br><span class="line">            <span class="comment">#给请求头中添加客户端IP</span></span><br><span class="line">            proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">            <span class="comment">#将$remote_addr变量值添加在客户端“X-Forwarded-For”请求头的后面，并以逗号分隔。 如果客户端请求未携带“X-Forwarded-For”请求头，$proxy_add_x_forwarded_for变量值将与$remote_addr变量相同  </span></span><br><span class="line">            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">            <span class="comment">#给请求头中添加客户端的Cookie</span></span><br><span class="line">            proxy_set_header Cookie $http_cookie;</span><br><span class="line">            <span class="comment">#将使用代理服务器的主域名和端口号来替换。如果端口是80，可以不加。</span></span><br><span class="line">            proxy_redirect off;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#浏览器对 Cookie 有很多限制，如果 Cookie 的 Domain 部分与当前页面的 Domain 不匹配就无法写入。</span></span><br><span class="line">            <span class="comment">#所以如果请求 A 域名，服务器 proxy_pass 到 B 域名，然后 B 服务器输出 Domian=B 的 Cookie，</span></span><br><span class="line">            <span class="comment">#前端的页面依然停留在 A 域名上，于是浏览器就无法将 Cookie 写入。</span></span><br><span class="line"></span><br><span class="line">　　         <span class="comment">#不仅是域名，浏览器对 Path 也有限制。我们经常会 proxy_pass 到目标服务器的某个 Path 下，</span></span><br><span class="line">            <span class="comment">#不把这个 Path 暴露给浏览器。这时候如果目标服务器的 Cookie 写死了 Path 也会出现 Cookie 无法写入的问题。</span></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置“Set-Cookie”响应头中的domain属性的替换文本，其值可以为一个字符串、正则表达式的模式或一个引用的变量</span></span><br><span class="line">            <span class="comment">#转发后端服务器如果需要Cookie则需要将cookie domain也进行转换，否则前端域名与后端域名不一致cookie就会无法存取</span></span><br><span class="line"></span><br><span class="line">　　　　　　  <span class="comment">#配置规则：proxy_cookie_domain serverDomain(后端服务器域) nginxDomain(nginx服务器域)</span></span><br><span class="line">            proxy_cookie_domain localhost .testcaigou800.com;</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment">#取消当前配置级别的所有proxy_cookie_domain指令</span></span><br><span class="line">            <span class="comment">#proxy_cookie_domain off;</span></span><br><span class="line">            <span class="comment">#与后端服务器建立连接的超时时间。一般不可能大于75秒；</span></span><br><span class="line">            proxy_connect_timeout <span class="number">30</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        error_page   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /<span class="number">50</span>x.html;</span><br><span class="line">        location = /<span class="number">50</span>x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">　　<span class="comment">#当需要对同一端口监听多个域名时，使用如下配置，端口相同域名不同，server_name也可以使用正则进行配置</span></span><br><span class="line">　　<span class="comment">#但要注意server过多需要手动扩大server_names_hash_bucket_size缓存区大小</span></span><br><span class="line">　　server &#123;</span><br><span class="line">　　　　listen <span class="number">80</span>;</span><br><span class="line">　　　　server_name www.abc.com;</span><br><span class="line">　　　　charset utf<span class="number">-8</span>;</span><br><span class="line">　　　　location / &#123;</span><br><span class="line">　　　　　　proxy_pass http://localhost:<span class="number">10001</span>;</span><br><span class="line">　　　　&#125;</span><br><span class="line">　　&#125;</span><br><span class="line">　　server &#123;</span><br><span class="line">　　　　listen <span class="number">80</span>;</span><br><span class="line">　　　　server_name aaa.abc.com;</span><br><span class="line">　　　　charset utf<span class="number">-8</span>;</span><br><span class="line">　　　　location / &#123;</span><br><span class="line">　　　　　　proxy_pass http://localhost:<span class="number">20002</span>;</span><br><span class="line">　　　　&#125;</span><br><span class="line">　　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Nginx反向代理详解"><a href="#Nginx反向代理详解" class="headerlink" title="Nginx反向代理详解"></a>Nginx反向代理详解</h2><h3 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h3><p><strong>正向代理代理客户端，反向代理代理服务器。</strong></p><h4 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h4><p>正向代理指的是，一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。</p><h4 id="反向代理-1"><a href="#反向代理-1" class="headerlink" title="反向代理"></a>反向代理</h4><p>反向代理（Reverse Proxy）方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</p><h3 id="为什么使用反向代理？"><a href="#为什么使用反向代理？" class="headerlink" title="为什么使用反向代理？"></a>为什么使用反向代理？</h3><ul><li>可以起到保护网站安全的作用，因为任何来自Internet的请求都必须先经过代理服务器。</li><li>通过缓存静态资源，加速Web请求。</li><li>实现负载均衡。目前市面上，主流的负载均衡方案：硬件设备有F5，软件方案有四层负载均衡的LVS，七层负载均衡的Nginx、Haproxy等。</li></ul><p><strong>链接：<a href="https://www.cnblogs.com/ysocean/p/9392908.html#_label3">nginx 反向代理详解</a></strong></p><h3 id="Nginx的Master-Worker模式"><a href="#Nginx的Master-Worker模式" class="headerlink" title="Nginx的Master-Worker模式"></a>Nginx的Master-Worker模式</h3><p>启动Nginx后，其实就是在80端口启动了Socket服务进行监听，如图所示，Nginx涉及Master进程和Worker进程。</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/nginx-Master-Worker.jpg" alt="nginx-Master-Worker"></p><h4 id="Master进程的作用"><a href="#Master进程的作用" class="headerlink" title="Master进程的作用"></a>Master进程的作用</h4><p>读取并验证配置文件nginx.conf；管理worker进程；</p><h4 id="Worker进程的作用"><a href="#Worker进程的作用" class="headerlink" title="Worker进程的作用"></a>Worker进程的作用</h4><p>每一个Worker进程都维护一个线程（避免线程切换），处理连接和请求；注意Worker进程的个数由配置文件决定，一般和CPU个数相关（有利于进程切换），配置几个就有几个Worker进程。</p><h2 id="Nginx负载均衡"><a href="#Nginx负载均衡" class="headerlink" title="Nginx负载均衡"></a>Nginx负载均衡</h2><p>在反向代理中，可以通过proxy_pass来指定Tomcat的地址，很显然只能指定一台Tomcat地址，那么如果想指定多台来达到负载均衡呢？</p><p>第一，通过<strong>upstream</strong>来定义一组Tomcat，并指定负载策略（IPHASH、加权论调、最少连接），健康检查策略（Nginx可以监控这一组Tomcat的状态）等。</p><p>第二，将proxy_pass替换成upstream指定的值即可。</p><h3 id="负载均衡可能带来的问题"><a href="#负载均衡可能带来的问题" class="headerlink" title="负载均衡可能带来的问题"></a>负载均衡可能带来的问题</h3><p>负载均衡所带来的明显的问题是，一个请求，可以到A server，也可以到B server，这完全不受控制，当然这也不是什么问题，只是得注意：<strong>用户状态的保存问题，如Session会话信息，不能在保存到服务器上。</strong></p><h3 id="查看链接：-nginx-负载均衡详解"><a href="#查看链接：-nginx-负载均衡详解" class="headerlink" title="查看链接： nginx 负载均衡详解"></a>查看链接： <a href="https://www.cnblogs.com/ysocean/p/9392912.html">nginx 负载均衡详解</a></h3><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="Nginx如何做到热部署？"><a href="#Nginx如何做到热部署？" class="headerlink" title="Nginx如何做到热部署？"></a>Nginx如何做到热部署？</h3><p>所谓热部署，就是配置文件nginx.conf修改后，不需要stop Nginx，不需要中断请求，就能让配置文件生效。（nginx -s reload 重新加载/nginx -t检查配置/nginx -s stop）</p><p>worker进程负责处理具体的请求，那么如果想达到热部署的效果，可以想象：</p><p><strong>方案一：</strong></p><p>修改配置文件nginx.conf后，主进程master负责推送给woker进程更新配置信息，woker进程收到信息后，更新进程内部的线程信息。（有点valatile的味道）</p><p><strong>方案二：</strong></p><p>修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可。</p><p><strong>Nginx采用的就是方案二来达到热部署的。</strong></p><h3 id="Nginx如何做到高并发下的高效处理？"><a href="#Nginx如何做到高并发下的高效处理？" class="headerlink" title="Nginx如何做到高并发下的高效处理？"></a>Nginx如何做到高并发下的高效处理？</h3><p>Nginx的worker进程个数与CPU绑定、worker进程内部包含一个线程高效回环处理请求，这的确有助于效率，但这是不够的。</p><p>要同时处理那么多的请求，要知道，有的请求需要发生IO，可能需要很长时间，如果等着它，就会拖慢worker的处理速度。</p><p><strong>Nginx采用了Linux的epoll模型，epoll模型基于事件驱动机制，它可以监控多个事件是否准备完毕，如果OK，那么放入epoll队列中，这个过程是异步的。worker只需要从epoll队列循环处理即可。</strong></p><h3 id="Nginx挂掉怎么办？"><a href="#Nginx挂掉怎么办？" class="headerlink" title="Nginx挂掉怎么办？"></a>Nginx挂掉怎么办？</h3><p><strong>Keepalived+Nginx实现高可用</strong>。</p><p>Keepalived是一个高可用解决方案，主要是用来防止服务器单点发生故障，可以通过和Nginx配合来实现Web服务的高可用。（其实，Keepalived不仅仅可以和Nginx配合，还可以和很多其他服务配合）</p><p>Keepalived+Nginx实现高可用的思路：</p><p>第一：请求不要直接打到Nginx上，应该先通过Keepalived（这就是所谓虚拟IP，VIP）</p><p>第二：Keepalived应该能监控Nginx的生命状态（提供一个用户自定义的脚本，定期检查Nginx进程状态，进行权重变化,，从而实现Nginx故障切换）</p><p><img src= "/img/loading.gif" data-lazy-src="https://raw.githubusercontent.com/fluetty/clouding/main/data/nginx+keepalived.jpg" alt="nginx+keepalived"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://zhuanlan.zhihu.com/p/34943332">8分钟带你深入浅出搞懂Nginx</a><br><a href="https://www.cnblogs.com/ysocean/p/9392908.html#_label3">nginx 反向代理详解</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络面试题目</title>
      <link href="2020/10/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/"/>
      <url>2020/10/19/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="浏览器输入URL发生了什么-TODO-详细描述"><a href="#浏览器输入URL发生了什么-TODO-详细描述" class="headerlink" title="浏览器输入URL发生了什么   TODO   详细描述"></a>浏览器输入URL发生了什么   TODO   详细描述</h3><ol><li>DNS解析        优先查找本地host文件有无对应的IP地址，没有的话去本地DNS服务器查找，还不行的话，本地DNS服务器会去找根DNS服务器要一个域服务器的地址进行查询，域服务器将要查询的域名的解析服务器地址返回给本地DNS，本地DNS去这里查询就OK了。</li><li>TCP连接        建立TCP/IP连接，服务器接收到请求并开始处理。</li><li>发送HTTP请求        浏览器拿到服务器的IP地址后，会向它发送HTTP请求。HTTP请求经由一层层的处理、封装、发出之后，最终经由网络到达服务器。</li><li>服务器处理HTTP请求并返回HTTP报文    服务器构建响应，再经由一层层的处理、封装、发出后，到达客户端，浏览器处理请求。</li><li>浏览器解析渲染页面        浏览器开始渲染页面，解析HTML，构建render树，根据render树的节点和CSS的对应关系，进行布局，绘制页面。</li><li>连接结束</li></ol><h3 id="TCP和UDP区别"><a href="#TCP和UDP区别" class="headerlink" title="TCP和UDP区别"></a>TCP和UDP区别</h3><ol><li>TCP 面向连接，传输可靠；  传输形式：字节流； 传输效率慢，所需资源多； 应用场景：要求通信数据可靠（如文件传输、邮件传输、远程登录等） 首部字节 20-60</li><li>UDP 无连接，传输不可靠；传输形式：数据报文段；传输效率快，所需资源少；应用场景：要求通信速度高（如即时通信，直播、域名转换等），首部8个字节（由四个字段组成）</li><li>TCP 不提供广播或者多播服务</li></ol><h3 id="TCP是如何保证传输可靠性"><a href="#TCP是如何保证传输可靠性" class="headerlink" title="TCP是如何保证传输可靠性"></a>TCP是如何保证传输可靠性</h3><ol><li>应用程序被分割成TCP认为最适合发送的数据块</li><li>TCP给发送的每个包标号，接收方对数据包排序，把有序数据传送给应用层。</li><li>校验和：TCP将保持它的首部和数据的校验和。这是一个端到端的校验和，目的是监测数据传输过程中的变化。如果收到检验和有差错，将丢弃这个报文段和不确认收到此报文段。</li><li>TCP的接收端会丢弃重复的数据。</li><li>流量控制：TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。TCP利用滑动窗口来实现流量控制。</li><li>拥塞控制：拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。常用的方法就是：1. 慢开始、拥塞控制 2. 快重传、快恢复。</li><li>超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 </li></ol><h3 id="tcp连接的三次握手，四次挥手"><a href="#tcp连接的三次握手，四次挥手" class="headerlink" title="tcp连接的三次握手，四次挥手"></a>tcp连接的三次握手，四次挥手</h3><h4 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h4><p>同步序号SYN：用来建立连接，涉及到TCP的三次握手。    </p><ol><li>开始建立连接时，客户端向服务器发送一个TCP分组，分组首部的SYN为1，并携带一个初始序号，表明这是一个连接请求。</li><li>如果服务器接受了连接，会向客户端发送一个TCP分组，分组中会包含SYN和ACK，都为1，同时包含一个确认序号，值为来自客户端的初始序号 + 1，表示连接已经被接受。</li><li>客户端收到上一步发来的分组后，会再向服务器发送一段确认报文分组，ACK为1，会再次携带确认序号，值是第二步来自客户端的确认序号 + 1。服务端收到确认信息后，进入已经连接的状态。<br> 在第三步的确认分组中，是可以携带要发送的数据的。</li></ol><h4 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h4><p>连接终止标志FIN： 用来关闭连接，当一端完成数据发送任务后会发送一个FIN标志来终止连接，但因为TCP在两个方向（C-S,S-C）上会有数据传递，每个方向有各自的发送FIN &amp; 确认关闭流程，所以会有四次交互，也称为四次挥手。    </p><ol><li>如果客户端应用层的数据发送完毕，会导致客户端的TCP报文发送一个FIN，告知服务器准备关闭数据传送。</li><li>服务器接收到这个标志后，它发回一个ACK，确认序号为收到的序号加1，同时TCP还要向应用程序发一个文件结束符。</li><li>此时服务器关闭这个方向的连接，导致它的TCP也会发送一个FIN。</li><li>客户端接收到之后发回一个确认ACK，序号为收到的序号 + 1，连接完全关闭。</li></ol><h3 id="描述HTTPS和HTTP的区别"><a href="#描述HTTPS和HTTP的区别" class="headerlink" title="描述HTTPS和HTTP的区别"></a>描述HTTPS和HTTP的区别</h3><ol><li>http是超文本传输协议，信息是明文传输，客户端和服务端无法验证对方的身份，https则是具有安全性的ssl/tls加密传输协议，ssl/tls运行在TCP之上。传输加密，加密采用对称加密，对称加密事务密匙用服务器方的证书进行了非对称加密。 http安全性不如https，https耗费服务器资源多。</li><li>http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。</li><li>对称加密：密钥只有一个，加密解密用同一个密码，加密速度快。典型的加密算法有AES、DES。</li><li>非对称加密：密钥成对出现（根据公钥无法推知私钥，根据私钥无法推知公钥）加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢。典型的非对称加密算法有RSA、DSA等。</li></ol><h3 id="HTTP协议的请求报文和响应报文格式"><a href="#HTTP协议的请求报文和响应报文格式" class="headerlink" title="HTTP协议的请求报文和响应报文格式"></a>HTTP协议的请求报文和响应报文格式</h3><p><strong>HTTP 请求报文由请求行、请求头部、空行 和 请求体 4 个部分组成。</strong></p><ol><li>请求行：请求行由方法字段、URL 字段 和HTTP 协议版本字段 3 个部分组成，他们之间使用空格隔开。<br>常用的 HTTP 请求方法有 GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT;</li><li>请求头部：请求头部由关键字/值对组成，每行一对，关键字和值用英文冒号“:”分隔。请求头部通知服务器有关于客户端请求的信息，典型的请求头有：User-Agent：产生请求的浏览器类型;Accept-Encoding：客户端可接受的编码压缩格式;Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie;等</li></ol><p><strong>HTTP 响应报文由状态行、响应头部、空行 和 响应包体 4 个部分组成。</strong></p><ol><li>状态行：状态行由 HTTP 协议版本字段、状态码和状态码的描述文本 3 个部分组成，他们之间使用空格隔开。</li></ol><h3 id="HTTP的状态码有哪些？如果出现某些错误的状态码，分析出是什么情况吗？"><a href="#HTTP的状态码有哪些？如果出现某些错误的状态码，分析出是什么情况吗？" class="headerlink" title="HTTP的状态码有哪些？如果出现某些错误的状态码，分析出是什么情况吗？"></a>HTTP的状态码有哪些？如果出现某些错误的状态码，分析出是什么情况吗？</h3><ol><li>状态码由三位数字组成，第一位数字表示响应的类型，常用的状态码有五大类如下所示：<br>　　1xx：表示服务器已接收了客户端请求，客户端可继续发送请求;<br>　　2xx：表示服务器已成功接收到请求并进行处理;<br>　　3xx：表示服务器要求客户端重定向;<br>　　4xx：表示客户端的请求有非法内容;<br>　　5xx：表示服务器未能正常处理客户端的请求而出现意外错误;</li><li>状态码描述文本有如下取值：<br>　　200 OK：表示客户端请求成功;<br>　　400 Bad Request：表示客户端请求有语法错误，不能被服务器所理解;<br>　　401 Unauthonzed：表示请求未经授权，该状态代码必须与 WWW-Authenticate 报头域一起使用;<br>　　403 Forbidden：表示服务器收到请求，但是拒绝提供服务，通常会在响应正文中给出不提供服务的原因;<br>　　404 Not Found：请求的资源不存在，例如，输入了错误的URL;<br>　　500 Internal Server Error：表示服务器发生不可预期的错误，导致无法完成客户端的请求;<br>　　503 Service Unavailable：表示服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常;</li></ol><h3 id="网络5层模型，每一层有哪些协议以及每一层的作用"><a href="#网络5层模型，每一层有哪些协议以及每一层的作用" class="headerlink" title="网络5层模型，每一层有哪些协议以及每一层的作用"></a>网络5层模型，每一层有哪些协议以及每一层的作用</h3><p>五层体系结构包括：应用层、运输层、网络层、数据链路层和物理层。<br>    图片</p><h3 id="网络IO模型有哪些？5种网络I-O模型"><a href="#网络IO模型有哪些？5种网络I-O模型" class="headerlink" title="网络IO模型有哪些？5种网络I/O模型"></a>网络IO模型有哪些？5种网络I/O模型</h3><ol><li>阻塞</li><li>非阻塞</li><li>I/O多路复用</li><li>信号驱动IO</li><li>异步I/O</li></ol><h3 id="Session和Cookie的作用是什么？有什么区别？"><a href="#Session和Cookie的作用是什么？有什么区别？" class="headerlink" title="Session和Cookie的作用是什么？有什么区别？"></a>Session和Cookie的作用是什么？有什么区别？</h3><p>Cookie和Session都是用来跟踪浏览器用户身份的会话方式。<br>Session的主要作用就是通过服务端记录用户的状态。Session数据保存在服务器端。安全性相对较高。<br>Cookie一般用于保存用户信息。Cookie数据保存在客户端（浏览器端）</p><h3 id="Cookie被禁用怎么办？"><a href="#Cookie被禁用怎么办？" class="headerlink" title="Cookie被禁用怎么办？"></a>Cookie被禁用怎么办？</h3><p>最常用的就是利用URL重写把Session ID直接附加在URL路径后。</p><h3 id="HTTP1-0和HTTP1-1的主要区别是什么？"><a href="#HTTP1-0和HTTP1-1的主要区别是什么？" class="headerlink" title="HTTP1.0和HTTP1.1的主要区别是什么？"></a>HTTP1.0和HTTP1.1的主要区别是什么？</h3><ol><li>长连接：HTTP1.0中，默认使用短连接，每次请求都要重新建立一次连接。HTTP1.1默认使用长连接，默认开启Connection:keep-alive. HTTP1.1的持续连接有非流水线方式和流水线方式。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。</li><li>错误状态响应码：HTTP1.1中新增了24个错误状态响应码，如409表示请求资源与资源当前状态发生冲突；410表示服务器上某资源被永久删除。</li><li>缓存处理：HTTP1.0中主要使用Header里的If-Modified-Since, Expires作为缓存判断的标准；HTTP1.1引入了更多的缓存控制策略，如Entity tag;If-Match，If-None-Match等更多可供选择的缓存头来控制缓存策略。</li><li>带宽优化及网络连接的使用：1.0不支持断点续传，存在浪费带宽现象；1.1在请求头引入range头域，允许只请求资源的某个部分，返回状态码是206（Partial Content），方便自由选择以便于充分利用带宽和连接。</li></ol><h3 id="URI和URL的区别是什么？"><a href="#URI和URL的区别是什么？" class="headerlink" title="URI和URL的区别是什么？"></a>URI和URL的区别是什么？</h3><ol><li>URI(Uniform Resource Identifier)是统一资源标志符，可唯一标识一个资源。</li><li>URL(Uniform Resource Location)是统一资源定位符，可提供该资源的路径。它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何Locate这个资源。</li><li>URI的作用像身份证号，URL的作用更像家庭住址。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。</li></ol><h3 id="HTTP-协议包括哪些请求？"><a href="#HTTP-协议包括哪些请求？" class="headerlink" title="HTTP 协议包括哪些请求？"></a>HTTP 协议包括哪些请求？</h3><p>超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。</p><ul><li>GET：请求读取由URL所标志的信息。</li><li>POST：给服务器添加信息（如注释）。</li><li>PUT：在给定的URL下存储一个文档。</li><li>DELETE：删除给定的URL所标志的资源。</li></ul><h3 id="HTTP-中，-POST-与-GET-的区别"><a href="#HTTP-中，-POST-与-GET-的区别" class="headerlink" title="HTTP 中， POST 与 GET 的区别"></a>HTTP 中， POST 与 GET 的区别</h3><ol><li>Get是从服务器上获取数据，Post是向服务器传送数据。</li><li>Get是把参数数据队列加到提交表单的Action属性所指向的URL中，值和表单内各个字段一一对应，在URL中可以看到。</li><li>Get传送的数据量小，不能大于2KB；Post传送的数据量较大，一般被默认为不受限制。</li><li>根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。<br> 4.1  所谓 安全的 意味着该操作用于获取信息而非修改信息。换句话说，GET请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。<br> 4.2  幂等 的意味着对同一URL的多个请求应该返回同样的结果。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis常考面试题目</title>
      <link href="2020/10/11/Redis%E5%B8%B8%E8%80%83%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/"/>
      <url>2020/10/11/Redis%E5%B8%B8%E8%80%83%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h3><ol><li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</li><li>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</li><li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li><li>使用多路I/O复用模型，非阻塞IO；</li><li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li></ol><h3 id="Redis支持的数据类型和使用场景"><a href="#Redis支持的数据类型和使用场景" class="headerlink" title="Redis支持的数据类型和使用场景"></a>Redis支持的数据类型和使用场景</h3><ol><li>String  常规计数：微博数，粉丝数等。</li><li>Hash 适合存储对象</li><li>List 底层实现为双向链表，可反向查找和遍历。 应用场景：微博的关注列表，粉丝列表，消息列表等。</li><li>Set 可以自动去重   应用场景：共同关注、共同粉丝等。</li><li>Sorted Set 权重score使得集合中的元素可以按照score有序排列。 应用场景：礼物排行榜</li><li>5.0后Stream</li></ol><h3 id="Redis和Memecache的区别？"><a href="#Redis和Memecache的区别？" class="headerlink" title="Redis和Memecache的区别？"></a>Redis和Memecache的区别？</h3><ol><li>在数据类型支持方面  Redis在数据支持上要比memecache多,Redis不仅仅支持简单的k/v类型的数据结构，同时还提供list,set,zset,hash等数据结构的存储。memcache支持简单的数据类型String.</li><li>在存储方式方面   Memecache把数据全部存在内存之中，不能持久化数据； Redis支持数据的持久化（RDB和AOF两种）； </li><li>集群模式： Memecache没有原生的集群模式，需要依靠客户端实现往集群中分片写入数据；Redis原生支持cluster模式。</li><li>Memecache是多线程的，非阻塞IO复用的网络模型；Redis使用单线程的多路IO复用模型。</li></ol><h3 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h3><ol><li>快照（snapshotting）持久化（RDB） RDB是在不同的时间点，将Redis某一时刻的数据生成快照并存储到磁盘上。</li><li>AOF（append-only file）持久化  AOF是只允许追加不允许改写文件，是将Redis执行过的所有写指令记录下来，在下次redis重启的时候，只要把这些写指令从前到后重复执行一遍，就可以实现数据恢复。</li></ol><h3 id="Redis的缓存雪崩和缓存击穿"><a href="#Redis的缓存雪崩和缓存击穿" class="headerlink" title="Redis的缓存雪崩和缓存击穿"></a>Redis的缓存雪崩和缓存击穿</h3><p> <strong>缓存雪崩 ：</strong>缓存同一时间大面积失效，请求落到数据库上，短时间内数据库因承受大量请求而崩掉。 </p><ul><li>事前：尽量保证Redis集群的高可用性，选择合适的内存淘汰策略。</li><li>事中：本地ehcache缓存 + hystrix限流降级，避免数据库崩掉        </li><li>事后：利用Redis持久化机制保存的数据尽快恢复缓存。</li></ul><p><strong>缓存击穿：</strong> 大量请求的key不存在于缓存，导致大量请求不经过缓存这一层直接访问数据库。<br>解决方法： </p><ul><li>缓存无效key 若某个key缓存数据库都查不到，将其写入到redis并设置过期时间。</li><li>布隆过滤器</li></ul><h3 id="为什么redis的操作是原子的？"><a href="#为什么redis的操作是原子的？" class="headerlink" title="为什么redis的操作是原子的？"></a>为什么redis的操作是原子的？</h3><p>原子性是数据库的事务中的特性。在数据库事务的情景下，原子性指的是：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。</p><p>对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。<br>Redis的操作之所以是原子性的，是因为<strong>Redis是单线程的。</strong></p><h3 id="Redis缓存淘汰策略"><a href="#Redis缓存淘汰策略" class="headerlink" title="Redis缓存淘汰策略"></a>Redis缓存淘汰策略</h3><p>6种数据淘汰策略：</p><ul><li>volatile-lru：从已设置过期时间的数据中挑选最近最少使用的数据淘汰；</li><li>volatile-ttl：从已设置过期时间的数据中挑选将要过期的数据淘汰；</li><li>volatile-random：从已设置过期时间的数据中任意选择数据淘汰；</li><li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰；</li><li> allkeys-random：从数据集中任意选择数据淘汰；</li><li>no-enviction（驱逐）：禁止驱逐数据</li></ul><p>注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。</p><p>建议使用策略规则：<br>　1.  <em>如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru</em><br>　2.  <em>如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random</em></p><h3 id="BloomFilter的原理"><a href="#BloomFilter的原理" class="headerlink" title="BloomFilter的原理"></a>BloomFilter的原理</h3><p>它实际上是一个很长的二进制向量和一系列随机映射函数。</p><p>布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p><p>Bloom Filter 是一种空间效率很高的随机数据结构，Bloom filter 可以看做是对 bit-map 的扩展, 它的原理是：</p><p>当一个元素被加入集合时，通过 K 个 Hash 函数将这个元素映射成一个位阵列（Bit array）中的 K 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它。</p><p>如果这些点有任何一个 0，则被检索元素一定不在；如果都是 1，则被检索元素很可能在。</p><h3 id="zset底层存储结构"><a href="#zset底层存储结构" class="headerlink" title="zset底层存储结构"></a>zset底层存储结构</h3><p>zset底层的存储结构包括ziplist或skiplist，在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，<br>两个条件如下：</p><ol><li>有序集合保存的元素数量小于128个</li><li>有序集合保存的所有元素的长度小于64字节</li></ol><p>当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。</p><p> 当skiplist作为zset的底层存储结构的时候，使用skiplist按序保存元素及分值，使用dict来保存元素和分值的映射关系。</p>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql面试高频题目</title>
      <link href="2020/10/07/Mysql%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91%E9%A2%98%E7%9B%AE/"/>
      <url>2020/10/07/Mysql%E9%9D%A2%E8%AF%95%E9%AB%98%E9%A2%91%E9%A2%98%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="说说MySQL有哪些存储引擎、都有哪些区别"><a href="#说说MySQL有哪些存储引擎、都有哪些区别" class="headerlink" title="说说MySQL有哪些存储引擎、都有哪些区别"></a>说说MySQL有哪些存储引擎、都有哪些区别</h2><ol><li>一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求。常见的存储引擎就 InnoDB、MyISAM、Memory、NDB。InnoDB 是 MySQL 默认的存储引擎，支持事务、行级锁定和外键。</li><li>InnoDB 支持事务，MyISAM不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；</li><li>InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；</li><li>InnoDB 是聚簇索引，MyISAM 是非聚簇索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。</li><li>InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；</li><li>InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一</li></ol><h3 id="一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15-16-17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15-？"><a href="#一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15-16-17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15-？" class="headerlink" title="一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？"></a>一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？</h3><ol><li>如果表的类型是MyISAM，那么是18。因为MyISAM表会把自增主键的最大ID 记录到数据文件中，重启MySQL自增主键的最大ID也不会丢失；</li><li>如果表的类型是InnoDB，那么是15。因为InnoDB 表只是把自增主键的最大ID记录到内存中，所以重启数据库或对表进行OPTION操作，都会导致最大ID丢失。</li></ol><h3 id="哪个存储引擎执行-select-count-更快，为什么"><a href="#哪个存储引擎执行-select-count-更快，为什么" class="headerlink" title="哪个存储引擎执行 select count(*) 更快，为什么"></a>哪个存储引擎执行 select count(*) 更快，为什么</h3><ol><li>MyISAM更快，因为MyISAM内部维护了一个计数器，可以直接调取。在 MyISAM 存储引擎中，把表的总行数存储在磁盘上，当执行 select count(*) from t 时，直接返回总数据。</li><li>在 InnoDB 存储引擎中，跟 MyISAM 不一样，没有将总行数存储在磁盘上，当执行 select count(*) from t 时，会先把数据读出来，一行一行的累加，最后返回总数量。</li></ol><h2 id="为什么Mysql索引要用B-树不是B树"><a href="#为什么Mysql索引要用B-树不是B树" class="headerlink" title="为什么Mysql索引要用B+树不是B树"></a>为什么Mysql索引要用B+树不是B树</h2><p>用B+树不用B树考虑的是IO对性能的影响，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。</p><p>数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。</p><p>其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。</p><h4 id="为何不采用Hash方式？"><a href="#为何不采用Hash方式？" class="headerlink" title="为何不采用Hash方式？"></a>为何不采用Hash方式？</h4><p>因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。</p><p>而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。</p><p>哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。</p><h2 id="通俗地理解三个范式"><a href="#通俗地理解三个范式" class="headerlink" title="通俗地理解三个范式"></a>通俗地理解三个范式</h2><p>　　通俗地理解三个范式，对于数据库设计大有好处。在数据库设计中，为了更好地应用三个范式，就必须通俗地理解<br>　　三个范式(通俗地理解是够用的理解，并不是最科学最准确的理解)<br><strong>第一范式：</strong>1NF是对属性的原子性约束，要求属性具有原子性，不可再分解；<br><strong>第二范式：</strong>2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性；<br><strong>第三范式：</strong>3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。</p><p>　　没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降<br>　　低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理<br>　　数据模型设计时考虑。降低范式就是增加字段，允许冗余。</p><h2 id="MySQL索引分类"><a href="#MySQL索引分类" class="headerlink" title="MySQL索引分类"></a>MySQL索引分类</h2><ol><li>数据结构角度</li></ol><ul><li>B+树索引</li><li>Hash索引</li><li>Full-Text全文索引</li><li>R-Tree索引</li></ul><ol start="2"><li>从物理存储角度</li></ol><ul><li>聚集索引（clustered index）</li><li>非聚集索引（non-clustered index），也叫辅助索引（secondary index）</li><li>聚集索引和非聚集索引都是B+树结构</li></ul><ol start="3"><li>从逻辑角度</li></ol><ul><li>主键索引：主键索引是一种特殊的唯一索引，不允许有空值</li><li>普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引</li><li>多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合</li><li>唯一索引或者非唯一索引</li><li>空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建</li></ul><h2 id="哪些情况需要创建索引"><a href="#哪些情况需要创建索引" class="headerlink" title="哪些情况需要创建索引"></a>哪些情况需要创建索引</h2><ol><li>主键自动建立唯一索引</li><li>频繁作为查询条件的字段</li><li>查询中与其他表关联的字段，外键关系建立索引</li><li>单键/组合索引的选择问题，高并发下倾向创建组合索引</li><li>查询中排序的字段，排序字段通过索引访问大幅提高排序速度</li><li>查询中统计或分组字段</li></ol><h2 id="哪些情况不要创建索引"><a href="#哪些情况不要创建索引" class="headerlink" title="哪些情况不要创建索引"></a>哪些情况不要创建索引</h2><ol><li>表记录太少</li><li>经常增删改的表</li><li>数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义）</li><li>频繁更新的字段不适合创建索引（会加重IO负担）</li><li>where条件里用不到的字段不创建索引</li></ol><h2 id="MySQL中-in和-exists-的区别？"><a href="#MySQL中-in和-exists-的区别？" class="headerlink" title="MySQL中 in和 exists 的区别？"></a>MySQL中 in和 exists 的区别？</h2><ol><li>exists：<strong>exists对外表用loop逐条查询</strong>，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false</li><li>in：in查询相当于多个or条件的叠加  in在查询的时候，首先查询子查询的表，然后<strong>将内表和外表做一个笛卡尔积</strong>，然后按照条件进行筛选。所以相对内表比较小的时候，in的速度较快。</li><li>如果查询的两个表大小相当，那么用in和exists差别不大。如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in</li></ol><h2 id="哪些情况会使索引失效？"><a href="#哪些情况会使索引失效？" class="headerlink" title="哪些情况会使索引失效？"></a>哪些情况会使索引失效？</h2><ol><li>使用不等于（！= 或者&lt;&gt;）不能使用索引</li><li>单独的&gt;,&lt;,(有时会用到，有时不会)</li><li>like “%_” 百分号在前.</li><li>单独引用复合索引里非第一位置的索引列.</li><li>字符型字段为数字时在where条件里不添加引号.</li><li>对索引列进行运算.需要建立函数索引.</li><li>not in ,not exists.</li><li>当变量采用的是times变量，而表的字段采用的是date变量时.或相反情况。</li></ol><h2 id="事务的四大特性（ACID）"><a href="#事务的四大特性（ACID）" class="headerlink" title="事务的四大特性（ACID）"></a>事务的四大特性（ACID）</h2><h3 id="原子性（Atomicity）"><a href="#原子性（Atomicity）" class="headerlink" title="原子性（Atomicity）"></a>原子性（Atomicity）</h3><p>原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。</p><h3 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h3><p>一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。</p><h3 id="隔离性（Isolation）"><a href="#隔离性（Isolation）" class="headerlink" title="隔离性（Isolation）"></a>隔离性（Isolation）</h3><p>隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。</p><h3 id="持久性（Durability）"><a href="#持久性（Durability）" class="headerlink" title="持久性（Durability）"></a>持久性（Durability）</h3><p>持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。</p><p>　　例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务已经正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。</p><h2 id="不考虑事务的隔离性，可能会发生的几种问题"><a href="#不考虑事务的隔离性，可能会发生的几种问题" class="headerlink" title="不考虑事务的隔离性，可能会发生的几种问题"></a>不考虑事务的隔离性，可能会发生的几种问题</h2><ol><li>脏读<br> 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。</li><li>不可重复读<br> 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。</li><li>幻读<br> 相同的查询条件首次查询后，其他事务添加或删除了新的数据，再次查询不一致</li></ol><h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><p>数据库事务的隔离级别有4种，由低到高分别为</p><ul><li> READ-UNCOMMITTED(未提交读)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。</li><li>  READ-COMMITTED(已提交读)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。Oracle的默认事务隔离级别</li><li> REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 MySQL的默认事务隔离级别。</li><li> SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 开销过大</li></ul>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线程进程相关面试题</title>
      <link href="2020/10/05/%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>2020/10/05/%E7%BA%BF%E7%A8%8B%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="如何创建线程"><a href="#如何创建线程" class="headerlink" title="如何创建线程"></a>如何创建线程</h3><ol><li>继承Thread类    重写run方法</li><li>实现Runnable接口    重写run方法</li><li>实现Callable接口 Callable的 call() 方法可以返回值和抛出异常</li><li>可以使用Executor框架来创建线程池</li></ol><h3 id="Thread-类中的start-和-run-方法有什么区别？"><a href="#Thread-类中的start-和-run-方法有什么区别？" class="headerlink" title="Thread 类中的start() 和 run()方法有什么区别？"></a>Thread 类中的start() 和 run()方法有什么区别？</h3><p>start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。<br>当你调用run()方法的时候，只会是在原来的线程中调用执行，没有新的线程启动，start()方法才会启动新线程。</p><h3 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h3><p>首先从定义上理解就有所不同</p><ol><li>进程是具有一定独立功能的程序、它是系统进行资源分配和调度的一个独立单位，重点在系统调度和单独的单位，也就是说进程是可以独立运行的一段程序。</li><li>线程是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源。在运行时，只是暂用一些计数器、寄存器和栈 。</li></ol><h4 id="他们之间的关系"><a href="#他们之间的关系" class="headerlink" title="他们之间的关系"></a>他们之间的关系</h4><p>一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程（通常说的主线程）。<br>    资源分配给进程，同一进程的所有线程共享该进程的所有资源。<br>    线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。<br>    处理机分给线程，即真正在处理机上运行的是线程。<br>    线程是指进程内的一个执行单元，也是进程内的可调度实体。</p><h4 id="从三个角度来剖析二者之间的区别"><a href="#从三个角度来剖析二者之间的区别" class="headerlink" title="从三个角度来剖析二者之间的区别"></a>从三个角度来剖析二者之间的区别</h4><ol><li>调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。</li><li>并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可以并发执行。</li><li>拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。</li></ol><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><ol><li>协程，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程。</li><li>协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。</li></ol><h4 id="协程的好处"><a href="#协程的好处" class="headerlink" title="协程的好处"></a>协程的好处</h4><ol><li>无需线程上下文切换的开销</li><li>无需原子操作锁定及同步的开销</li><li>方便切换控制流，简化编程模型</li><li>高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。</li></ol><h4 id="协程的缺点"><a href="#协程的缺点" class="headerlink" title="协程的缺点"></a>协程的缺点</h4><ol><li>无法利用多核资源：协程的本质是个单线程,它不能同时将单个CPU的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。</li><li>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</li></ol><h3 id="多线程间通信方式"><a href="#多线程间通信方式" class="headerlink" title="多线程间通信方式"></a>多线程间通信方式</h3><ol><li>共享变量        线程间发送信号的一个简单方式是在共享对象的变量里设置信号值  synchronized </li><li>wait/notify机制        为了实现线程通信，我们可以使用Object类提供的wait()、notify()、notifyAll()三个方法。调用wait()方法会释放对该同步监视器的锁定。</li><li>Lock/Condition机制   如果程序不使用synchronized关键字来保持同步，而是直接使用Lock对象来保持同步，则系统中不存在隐式的同步监视器对象，也就不能使用wait()、notify()、notifyAll()来协调线程的运行.</li><li>管道</li></ol><h3 id="进程间通信方式"><a href="#进程间通信方式" class="headerlink" title="进程间通信方式"></a>进程间通信方式</h3><ol><li>管道（Pipe） ：管道可用于具有亲缘关系进程间的通信，允许一个进程和另一个与它有共同祖先的进程之间进行通信。</li><li>命名管道（named pipe） ：命名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令mkfifo或系统调用mkfifo来创建。</li><li>信号（Signal） ：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；Linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）。</li><li>消息（Message）队列 ：消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺</li><li>共享内存 ：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。</li><li>内存映射（mapped memory）：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。</li><li>信号量（semaphore） ：主要作为进程间以及同一进程不同线程之间的同步手段。</li><li>套接口（Socket） ：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：linux和System V的变种都支持套接字。</li></ol><h3 id="Java常见的线程安全的类实现方式"><a href="#Java常见的线程安全的类实现方式" class="headerlink" title="Java常见的线程安全的类实现方式"></a>Java常见的线程安全的类实现方式</h3><ol><li>通过synchronized 关键字给方法加上内置锁来实现线程安全    Timer，TimerTask，Vector，Stack，HashTable，StringBuffer</li><li>原子类Atomicxxx—包装类的线程安全类        如AtomicLong，AtomicInteger等等        Atomicxxx 是通过Unsafe 类的native方法实现线程安全的</li><li>BlockingQueue 和BlockingDeque<br>BlockingDeque接口继承了BlockingQueue接口，<br>BlockingQueue 接口的实现类有ArrayBlockingQueue ，LinkedBlockingQueue ，PriorityBlockingQueue 而BlockingDeque接口的实现类有LinkedBlockingDeque<br>BlockingQueue和BlockingDeque 都是通过使用定义为final的ReentrantLock作为类属性显式加锁实现同步的</li><li>CopyOnWriteArrayList和 CopyOnWriteArraySet<br>CopyOnWriteArraySet的内部实现是在其类内部声明一个final的CopyOnWriteArrayList属性，并在调用其构造函数时实例化该CopyOnWriteArrayList，CopyOnWriteArrayList采用的是显式地加上ReentrantLock实现同步，而CopyOnWriteArrayList容器的线程安全性在于在每次修改时都会创建并重新发布一个新的容器副本，从而实现可变性。</li><li>Concurrentxxx<br>最常用的就是ConcurrentHashMap，当然还有ConcurrentSkipListSet和ConcurrentSkipListMap等等。<br>ConcurrentHashMap使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性。ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只能有一个线程访问容器，而是使用一种粒度更细的加锁机制——分段锁来实现更大程度的共享；在这种机制中，任意数量的读取线程可以并发访问Map，执行读取操作的线程和执行写入操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发地修改Map，这使得在并发环境下吞吐量更高，而在单线程环境中只损失非常小的性能</li><li>ThreadPoolExecutor        ThreadPoolExecutor也是使用了ReentrantLock显式加锁同步</li><li>Collections中的synchronizedCollection(Collection c)方法可将一个集合变为线程安全，其内部通过synchronized关键字加锁同步</li></ol><h3 id="怎么判断乐观锁是否被修改过？"><a href="#怎么判断乐观锁是否被修改过？" class="headerlink" title="怎么判断乐观锁是否被修改过？"></a>怎么判断乐观锁是否被修改过？</h3><p>使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。</p><h3 id="产生死锁的四个必要条件，如何解决？"><a href="#产生死锁的四个必要条件，如何解决？" class="headerlink" title="产生死锁的四个必要条件，如何解决？"></a>产生死锁的四个必要条件，如何解决？</h3><ol><li>互斥条件：一个资源每次只能被一个进程使用。</li><li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li><li>不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。</li><li>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</li></ol><h3 id="处理死锁的思路如下："><a href="#处理死锁的思路如下：" class="headerlink" title="处理死锁的思路如下："></a>处理死锁的思路如下：</h3><ol><li>预防死锁：破坏四个必要条件中的一个或多个来预防死锁</li><li>避免死锁：在资源动态分配的过程中，用某种方式防止系统进入不安全的状态。</li><li>检测死锁：运行时产生死锁，及时发现思索，将程序解脱出来。</li><li>解除死锁：发生死锁后，撤销进程，回收资源，分配给正在阻塞状态的进程。</li></ol><h3 id="预防死锁的办法："><a href="#预防死锁的办法：" class="headerlink" title="预防死锁的办法："></a>预防死锁的办法：</h3><ol><li>破坏请求和保持条件：1.一次性的申请所有资源。之后不再申请资源，如果不满足资源条件则得不到资源分配。2.只获得初期资源运行，之后将运行完的资源释放，请求新的资源。</li><li>破坏不可抢占条件：当一个进程获得某种不可抢占资源，提出新的资源申请，若不能满足，则释放所有资源，以后需要，再次重新申请。</li><li>破坏循环等待条件：对资源进行排号，按照序号递增的顺序请求资源。若进程获得序号高的资源想要获取序号低的资源，就需要先释放序号高的资源。</li></ol><h3 id="死锁的解除办法："><a href="#死锁的解除办法：" class="headerlink" title="死锁的解除办法："></a>死锁的解除办法：</h3><ol><li>抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态。</li><li>终止（撤销）进程：将一个或多个思索进程终止（撤销），直至打破循环环路，使系统从死锁状态解脱。</li></ol><h3 id="Java锁有哪些，具体的原理是什么，之间有什么区别"><a href="#Java锁有哪些，具体的原理是什么，之间有什么区别" class="headerlink" title="Java锁有哪些，具体的原理是什么，之间有什么区别"></a>Java锁有哪些，具体的原理是什么，之间有什么区别</h3><ol><li>公平锁/非公平锁    公平锁是指多个线程按照申请锁的顺序来获取锁。非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。   对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS来实现线程调度，所以并没有任何办法使其变成公平锁。</li><li>可重入锁    可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。ReentrantLock Synchronized 是可重入锁。可重入锁的一个好处是可一定程度避免死锁。</li><li>独享锁/共享锁        独享锁是指该锁一次只能被一个线程所持有。共享锁是指该锁可被多个线程所持有。ReentrantLock Synchronized 是独享锁。Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。独享锁与共享锁也是通过AQS(AbstractQueuedSynchronizer)来实现的，通过实现不同的方法，来实现独享或者共享。</li><li>互斥锁/读写锁        互斥锁在Java中的具体实现就是ReentrantLock。    读写锁在Java中的具体实现就是ReadWriteLock</li><li>乐观锁/悲观锁        悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。悲观锁在Java中的使用，就是利用各种锁。乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新</li><li>分段锁    分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。        分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。</li><li>偏向锁/轻量级锁/重量级锁        锁的状态，并且是针对Synchronized。偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。<br>轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。<br>重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。</li><li>自旋锁    自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。</li></ol><h3 id="sleep-和wait-方法的区别和共同点"><a href="#sleep-和wait-方法的区别和共同点" class="headerlink" title="sleep()和wait()方法的区别和共同点"></a>sleep()和wait()方法的区别和共同点</h3><ol><li>最主要的区别是sleep()不释放锁，wait()会释放锁。</li><li>两者皆可暂停线程的执行。</li><li>wait()常用于线程交互/通信，sleep()常用于暂停执行。</li><li>wait()方法调用后，线程不会自动苏醒，需要别的线程调用同一对象的notify() 或notifyAll()方法。sleep()方法执行完，会自动苏醒。或者可以使用wait(long timeout)超时自动苏醒。</li></ol><h3 id="synchronized-底层是如何优化的"><a href="#synchronized-底层是如何优化的" class="headerlink" title="synchronized 底层是如何优化的"></a>synchronized 底层是如何优化的</h3><ol><li><p>在 Java 早期版本中，synchronized 属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。</p></li><li><p>JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM高频面试题目</title>
      <link href="2020/10/03/JVM%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/"/>
      <url>2020/10/03/JVM%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="简单描述一下JVM的内存模型"><a href="#简单描述一下JVM的内存模型" class="headerlink" title="简单描述一下JVM的内存模型"></a>简单描述一下JVM的内存模型</h3><p>jvm内存主要分为五个部分：<strong>方法区，java堆，java栈，程序计数器，本地方法栈。</strong></p><ol><li><strong>方法区（永久代，线程共享）</strong>：存储被虚拟机加载的类信息，常量，静态常量，静态方法，运行时常量池等。</li><li><strong>java堆（线程共享）</strong>：存放所有new出来的东西。    1.堆是java虚拟机所管理的内存区域中最大的一块，java堆是被所有线程共享的内存区域，在java虚拟机启动时创建，堆内存的唯一目的就是存放对象实例，几乎所有的对象实例都在堆内存分配空间。2.堆是GC管理的主要区域，从垃圾回收的角度看，由于现在的垃圾收集器都是采用的分代收集算法，因此java堆还可以初步细分为新生代和老年代。</li><li><strong>java栈（线程私有方法级）</strong>：为虚拟机执使用到的方法服务。每个方法被调用的时候都会创建一个栈帧，用于存储局部变量表、操作栈、动态链接、方法出口等信息。局部变量表存放的是：编译期可知的基本数据类型、对象引用类型。</li><li><strong>程序计数器（线程私有）</strong>：保证线程切换后能恢复到原来的位置。在线程创建时创建，指向下一条指令的地址，执行本地方法时，其值为undefined。为了线程切换后能够恢复到正确的执行位置，每条线程都有一个独立的程序计数器，这块儿属于“线程私有”的内存。</li><li><strong>本地方法栈（线程私有）</strong>：为虚拟机执使用到的Native方法服务。本地方法栈则为虚拟机执使用到的Native方法服务，本地方法栈也会抛出StackOverFlowError和OutOfMemoryError。</li></ol><h3 id="什么情况下会触发FullGC"><a href="#什么情况下会触发FullGC" class="headerlink" title="什么情况下会触发FullGC?"></a>什么情况下会触发FullGC?</h3><ol><li>System.gc()方法的调用。此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定，但很多情况下它会触发Full GC,从而增加Full GC的频率，也即增加了间歇性停顿的次数。</li><li>旧生代空间不足。旧生代空间只有在新生代对象转入及创建大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出错误：java.lang.OutOfMemoryError: Java heap space 。</li><li>Permanet Generation空间满了。Permanet Generation中存放的为一些class的信息等，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。</li><li>通过Minor GC后进入老年代的平均大小大于老年代的可用内存。如果发现统计数据说之前Minor GC的平均晋升大小比目前old gen剩余的空间大，则不会触发Minor GC而是转为触发full GC。</li><li>由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小</li></ol><h3 id="Java类加载器有几种，关系是怎么样的？"><a href="#Java类加载器有几种，关系是怎么样的？" class="headerlink" title="Java类加载器有几种，关系是怎么样的？"></a>Java类加载器有几种，关系是怎么样的？</h3><ol><li><strong>引导类加载器（启动类加载器）</strong> bootstrap class loader    由C++编写，无法通过程序得到。主要负责加载JAVA中的一些核心类库。它负责将 /lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中</li><li><strong>扩展类加载器</strong> extensions class loader    负责加载JAVA_HOME/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。</li><li><strong>系统类加载器</strong> application class loader    它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。</li><li><strong>自定义类加载器</strong> java.lang.classloder    通过继承java.lang.ClassLoader类的方式<h4 id="关系："><a href="#关系：" class="headerlink" title="关系："></a>关系：</h4>启动类加载器，由C++实现，没有父类。<br>拓展类加载器(ExtClassLoader)，由Java语言实现，父类加载器为null<br>系统类加载器(AppClassLoader)，由Java语言实现，父类加载器为ExtClassLoader<br>自定义类加载器，父类加载器肯定为AppClassLoader。</li></ol><h3 id="双亲委派机制的加载流程是怎样的，有什么好处？"><a href="#双亲委派机制的加载流程是怎样的，有什么好处？" class="headerlink" title="双亲委派机制的加载流程是怎样的，有什么好处？"></a>双亲委派机制的加载流程是怎样的，有什么好处？</h3><ol><li>虚拟机类加载机制：虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。</li><li>类从被加载到JVM中开始，到卸载为止，整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。</li><li>类加载过程包括加载、验证、准备、解析和初始化五个阶段。</li><li>某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。</li><li>使用双亲委派模型的好处在于Java类随着它的类加载器一起具备了一种带有优先级的层次关系。保证了Java程序的稳定运行，可以避免类的重复加载(JVM区分不同类的方式不仅仅是类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了Java的核心API不被篡改。每个类加载器加载自己有可能出现多个不同的但是名字相同的类。</li></ol><h3 id="简单讲一下类加载过程"><a href="#简单讲一下类加载过程" class="headerlink" title="简单讲一下类加载过程"></a>简单讲一下类加载过程</h3><ol><li>类加载过程包括加载、链接（验证、准备、解析）和初始化五个阶段。</li><li>加载：加载指的是把class字节码文件从各个来源通过类加载器装载入内存中。按照类加载器：一般包括启动类加载器，扩展类加载器，应用类加载器，以及用户的自定义类加载器。</li><li>验证：为了保证加载进来的字节流符合虚拟机规范，不会造成安全错误。文件格式的验证、元数据的验证、字节码的验证、符号引用的验证等</li><li>准备: 准备阶段是为类的静态变量分配内存，并将其初始化为默认值。</li><li>解析：把常量池中的符号引用转换为直接引用。</li><li>初始化：JVM负责主要对类变量(类变量就是static修改的变量)进行初始化。 方式：1.声明静态类变量时指定初始值    2.使用静态代码块为类变量指定初始值</li></ol><h3 id="Java8为什么用Metaspace替换掉PermGen？Metaspace保存在哪里？"><a href="#Java8为什么用Metaspace替换掉PermGen？Metaspace保存在哪里？" class="headerlink" title="Java8为什么用Metaspace替换掉PermGen？Metaspace保存在哪里？"></a>Java8为什么用Metaspace替换掉PermGen？Metaspace保存在哪里？</h3><ol><li>整个永久代有一个JVM本身设置的固定大小上限，无法进行调整，而原空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到java.lang.OutOfMemoryError。Metaspace将根据运行时的应用程序需求动态地调整大小。</li><li>元空间并不在虚拟机中，而是使用本地内存。</li></ol><h3 id="编译期会对指令做那些优化（简单描述编译器的指令重排）"><a href="#编译期会对指令做那些优化（简单描述编译器的指令重排）" class="headerlink" title="编译期会对指令做那些优化（简单描述编译器的指令重排）"></a>编译期会对指令做那些优化（简单描述编译器的指令重排）</h3><p>在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：</p><ol><li>编译器优化的重排序<br> 编译器在不改变单线程程序语义的前提下（代码中不包含synchronized关键字），可以重新安排语句的执行顺序。</li><li>指令级并行的重排序<br> 现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。    </li><li>内存系统的重排序。<br> 由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</li></ol><h3 id="简单描述一下volatile可以解决什么问题？如何做到的"><a href="#简单描述一下volatile可以解决什么问题？如何做到的" class="headerlink" title="简单描述一下volatile可以解决什么问题？如何做到的"></a>简单描述一下volatile可以解决什么问题？如何做到的</h3><ol><li>重排序是指编译器和处理器为了优化程序性能而对指令序列进行排序的一种手段。用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。</li><li>强制主内存读写同步，保证共享变量对所有线程的可见性。1.当写一个volatile变量时，JMM会把该线程对应的本地内存中的变量强制刷新到主内存中去；2.这个写会操作会导致其他线程中的缓存无效。</li></ol><h3 id="简单描述一下GC的分代回收"><a href="#简单描述一下GC的分代回收" class="headerlink" title="简单描述一下GC的分代回收"></a>简单描述一下GC的分代回收</h3><ol><li>Java的堆内存被分代回收，分代管理是为了方便垃圾回收。 1.大部分对象很快就不再使用；2.还有一部分不会立即无用，也不会持续很长时间。</li><li>虚拟机划分为年轻代、老年代、永久代。</li><li>年轻代主要存放新创建的对象，年轻代分为Eden区和了两个Survivor区。大部分对象在Eden区中生成。当Eden区满了，还存活的对象会在两个Survivor区中交替保存，达到一定次数会晋升到老年代。</li><li>老年代用来存放从年轻代晋升而来的，存活时间较长的对象。</li><li>永久代，主要保存类信息等内容，这里的永久代是指对象划分方式，不是专指 1.7 的 PermGen，或者 1.8 之后的 Metaspace。</li><li>根据年轻代与老年代的特点，JVM 提供了不同的垃圾回收算法。垃圾回收算法按类型可以分为引用计数法、复制法和标记清除法。</li><li>JVM 中提供的年轻代回收算法 Serial、ParNew、Parallel Scavenge都是复制算法，而 CMS、G1、ZGC 都属于标记清除算法。</li></ol><h3 id="G1垃圾回收算法和CMS的区别有哪些？"><a href="#G1垃圾回收算法和CMS的区别有哪些？" class="headerlink" title="G1垃圾回收算法和CMS的区别有哪些？"></a>G1垃圾回收算法和CMS的区别有哪些？</h3><blockquote><p>CMS：以获取最短回收停顿时间为目标的收集器，基于并发“标记清理”实现。    优点是并发收集，停顿小。</p></blockquote><p>过程：</p><ol><li>初始标记：独占CPU，仅标记GCroots能直接关联的对象</li><li>并发标记：可以和用户线程并行执行，标记所有可达对象</li><li>重新标记：独占CPU(STW)，对并发标记阶段用户线程运行产生的垃圾对象进行标记修正</li><li>并发清理：可以和用户线程并行执行，清理垃圾</li></ol><blockquote><p>G1：是一款面向服务端应用的垃圾收集器    并行于并发    分代收集    可预测的停顿</p></blockquote><p>过程：</p><ol><li>初始标记（Initial Making）</li><li>并发标记（Concurrent Marking）</li><li>最终标记（Final Marking）</li><li>筛选回收（Live Data Counting and Evacuation）</li></ol><h3 id="对象引用有哪几种方式，有什么特点？"><a href="#对象引用有哪几种方式，有什么特点？" class="headerlink" title="对象引用有哪几种方式，有什么特点？"></a>对象引用有哪几种方式，有什么特点？</h3><ol><li>强引用    代码中普遍存在的类似”Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。</li><li>软引用    描述有些还有用但并非必需的对象。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围进行二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。Java中的类SoftReference表示软引用。</li><li>弱引用        描述非必需对象。被弱引用关联的对象只能生存到下一次垃圾回收之前，垃圾收集器工作之后，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。Java中的类WeakReference表示弱引用。</li><li>虚引用    这个引用存在的唯一目的就是在这个对象被收集器回收时收到一个系统通知，被虚引用关联的对象，和其生存时间完全没关系。Java中的类PhantomReference表示虚引用。</li></ol><h3 id="简单说一下Java对象的创建过程"><a href="#简单说一下Java对象的创建过程" class="headerlink" title="简单说一下Java对象的创建过程"></a>简单说一下Java对象的创建过程</h3><ol><li>类加载检查   检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查符号引用代表的类是否已被加载、解析、初始化。若没有则执行类加载过程。</li><li>分配内存    虚拟机为新生对象分配内存。分配方式有”指针碰撞”和”空闲列表”两种，选取何种由Java堆是否规整决定，Java堆是否规整由所采用的垃圾收集器是否带有压缩整理功能决定。   内存分配并发问题两种方式保证线程安全： CAS+失败重试（CAS十的一种实现方式，虚拟机采用CAS配上失败重试的方式保证操作的原子性）  TLAB </li><li>初始化零值   虚拟机将分配的内存初始化为零值（不包括对象头）确保对象实例字段可不赋初值直接使用。</li><li>设置对象头    对对象进行设置 如这个对象是那个的实例 对象的hash码等</li><li>执行init方法  按照程序员的意愿进行初始化</li></ol><h3 id="如何判断对象是否已经死亡"><a href="#如何判断对象是否已经死亡" class="headerlink" title="如何判断对象是否已经死亡"></a>如何判断对象是否已经死亡</h3><ol><li>引用计数法    给对象加引用计数器，计数器为0的对象就是不可能再被使用的。</li><li>可达性分析算法   通过一系列的称为”GC Roots”的对象作为起点，从这些节点向下搜索，节点走过的路径称为引用链，当一个对象到GC Roots没有任何应用链相连，此对象不可用。</li></ol><h3 id="内存泄漏-内存溢出-解决或者避免的方法"><a href="#内存泄漏-内存溢出-解决或者避免的方法" class="headerlink" title="内存泄漏 内存溢出 解决或者避免的方法"></a>内存泄漏 内存溢出 解决或者避免的方法</h3><h4 id="内存泄露"><a href="#内存泄露" class="headerlink" title="内存泄露"></a>内存泄露</h4><p>是指程序在申请内存后，无法释放已申请的内存空间就造成了内存泄漏，一次内存泄漏似乎不会有大的影响，但内存泄漏堆积后的后果就是内存溢出。</p><h4 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h4><p>指程序申请内存时，没有足够的内存供申请者使用，或者说，给了你一块存储int类型数据的存储空间，但是你却存储long类型的数据，那么结果就是内存不够用，此时就会报错OOM,即所谓的内存溢出，简单来说就是自己所需要使用的空间比我们拥有的内存大内存不够使用所造成的内存溢出。</p><p>内存泄漏一般分为 常发性内存泄漏、偶发性内存泄漏、一次性内存泄漏、隐式内存泄漏。</p><p> <strong>解决方法</strong>：</p><ol><li>资源性对象在不使用的时候，应该调用它的close()函数将其关闭掉        </li><li>避免集中创建对象尤其是大对象，如果可以的话尽量使用流操作。</li></ol><h4 id="内存溢出原因"><a href="#内存溢出原因" class="headerlink" title="内存溢出原因"></a>内存溢出原因</h4><ol><li>内存中加载的数据量过于庞大，如一次从数据库取出过多数据；</li><li>集合类中有对对象的引用，使用完后未清空，产生了堆积，使得JVM不能回收；</li><li>代码中存在死循环或循环产生过多重复的对象实体；</li><li>使用的第三方软件中的BUG；</li><li>启动参数内存值设定的过小</li></ol><h4 id="内存溢出的解决方案"><a href="#内存溢出的解决方案" class="headerlink" title="内存溢出的解决方案"></a>内存溢出的解决方案</h4><ol><li>修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)</li><li>检查错误日志，查看“OutOfMemory”错误前是否有其 它异常或错误。</li><li>对代码进行走查和分析，找出可能发生内存溢出的位置。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java集合相关面试题</title>
      <link href="2020/10/02/Java%E9%9B%86%E5%90%88%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>2020/10/02/Java%E9%9B%86%E5%90%88%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="map-HashMap-HashTable-ConcurrentHashMap-必须阅读源码，必问题目"><a href="#map-HashMap-HashTable-ConcurrentHashMap-必须阅读源码，必问题目" class="headerlink" title="map HashMap  HashTable  ConcurrentHashMap (必须阅读源码，必问题目)"></a>map HashMap  HashTable  ConcurrentHashMap (必须阅读源码，必问题目)</h3><ol><li>父类不同  HashTable 继承 Dictionary，    HashMap 继承 abstractMap，它们都是Map接口的实现类 ，都是键值对集合。</li><li>最重要的区别：多线程同步特性不同    HashMap同一时间允许多个线程同时进行操作，效率相对较高 但是可能出现并发错误；Hashtable 同一时间只允许一个线程进行操作，效率相对较低 但是不会出现并发错误。</li><li>它们对于null的处理不同 HashMap 无论主键还是值对象，都可以存放null，只不过主键要求唯一，所以只能存放一个null；Hashtable对null零容忍，无论主键还是值 都不能添加null，否则直接出现异常。</li><li>它们底层实现的细节不同 HashMap 底层默认分16个小组 分组组数可以指定，但最终结果一定是2的n次方数（为什么呢）因为计算散列小组的时候 使用：x &amp; (分组组数-1)，效率高；    Hashtable 底层默认分11个小组，分组组数可以任意指定，计算散列小组的时候 使用：x %分组组数。</li><li>底层数据结构 JDK 1.8 前， 两者【底层数据结构】 = 【链表 + 数组 】；JDK1.8之后 HashMap 底层数据结构变化 ，链表长度过长(默认超过8时)，则链表树化为红黑树，提高搜索效率。</li><li>它们出现的版本不同     HashMap since JDK1.2；    Hashtable since JDK1.0</li></ol><h3 id="说说String中hashcode的实现"><a href="#说说String中hashcode的实现" class="headerlink" title="说说String中hashcode的实现"></a>说说String中hashcode的实现</h3><p><strong>源码：</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> h = hash;</span><br><span class="line"><span class="keyword">if</span> (h == <span class="number">0</span> &amp;&amp; value.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">char</span> val[] = value;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; value.length; i++) &#123;</span><br><span class="line">        h = <span class="number">31</span> * h + val[i];</span><br><span class="line">    &#125;</span><br><span class="line">    hash = h;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>String类中的hashCode计算方法还是比较简单的，就是以31为权，每一位为字符的ASCII值进行运算，用自然溢出来等效取模。</p><p>哈希计算公式可以计为s[0]*31^(n-1) + s[1]*31^(n-2) + … + s[n-1]</p><h4 id="那为什么以31为质数"><a href="#那为什么以31为质数" class="headerlink" title="那为什么以31为质数"></a>那为什么以31为质数</h4><p>主要是因为31是一个奇质数，所以31<em>i=32</em>i-i=(i&lt;&lt;5)-i，这种位移与减法结合的计算相比一般的运算快很多。</p><h3 id="说说jdk1-8中hashmap有什么变化"><a href="#说说jdk1-8中hashmap有什么变化" class="headerlink" title="说说jdk1.8中hashmap有什么变化"></a>说说jdk1.8中hashmap有什么变化</h3><ol><li>由数组+链表的结构改为数组+链表+红黑树。</li><li>优化了高位运算的hash算法：h^(h&gt;&gt;&gt;16)</li><li>扩容后，元素要么是在原位置，要么是在原位置再移动2次幂的位置，且链表顺序不变。<br> 发生hash碰撞时，java 1.7 会在链表的头部插入，而java 1.8会在链表的尾部插入。<br> 在java 1.8中，Entry被Node替代(换了一个马甲）<br>最后一条是重点，因为最后一条的变动，hashmap在1.8中，不会在出现死循环问题。</li></ol><h4 id="为什么在解决hash冲突的时候，不直接用红黑树，-而选择先用链表，再转红黑树"><a href="#为什么在解决hash冲突的时候，不直接用红黑树，-而选择先用链表，再转红黑树" class="headerlink" title="为什么在解决hash冲突的时候，不直接用红黑树， 而选择先用链表，再转红黑树"></a>为什么在解决hash冲突的时候，不直接用红黑树， 而选择先用链表，再转红黑树</h4><p>因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。 当元素小于8个当时候，此时做查询操作，链表结构已经能保证查询性能。<br>当元素大于8个的时候，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。<br>因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的。</p><h4 id="我不用红黑树，用二叉查找树可以么"><a href="#我不用红黑树，用二叉查找树可以么" class="headerlink" title="我不用红黑树，用二叉查找树可以么"></a>我不用红黑树，用二叉查找树可以么</h4><p>可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。</p><h3 id="当链表转为红黑树后，什么时候退化为链表"><a href="#当链表转为红黑树后，什么时候退化为链表" class="headerlink" title="当链表转为红黑树后，什么时候退化为链表"></a>当链表转为红黑树后，什么时候退化为链表</h3><p>为6的时候退转为链表。中间有个差值7可以防止链表和树之间频繁的转换。<br>假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，<br>如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。</p><h3 id="HashMap在并发编程环境下有什么问题"><a href="#HashMap在并发编程环境下有什么问题" class="headerlink" title="HashMap在并发编程环境下有什么问题"></a>HashMap在并发编程环境下有什么问题</h3><ol><li>多线程扩容，引起的死循环问题</li><li>多线程put的时候可能导致元素丢失</li><li>put非null元素后get出来的却是null<h3 id="在jdk1-8中还有这些问题么"><a href="#在jdk1-8中还有这些问题么" class="headerlink" title="在jdk1.8中还有这些问题么"></a>在jdk1.8中还有这些问题么</h3>在jdk1.8中，死循环问题已经解决。其他两个问题还是存在。</li></ol><h3 id="你一般怎么解决这些问题的？"><a href="#你一般怎么解决这些问题的？" class="headerlink" title="你一般怎么解决这些问题的？"></a>你一般怎么解决这些问题的？</h3><p>比如ConcurrentHashmap，Hashtable等线程安全等集合类。</p><h3 id="解决hash冲突的方法"><a href="#解决hash冲突的方法" class="headerlink" title="解决hash冲突的方法"></a>解决hash冲突的方法</h3><p>比较出名的有四种</p><ol><li> 开放定址法    一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入.</li><li> 链地址法     链地址法的基本思想是：每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来。</li><li>再哈希法  再哈希法又叫双哈希法，有多个不同的Hash函数，当发生冲突时，使用第二个，第三个，….，等哈希函数计算地址，直到无冲突。虽然不易发生聚集，但是增加了计算时间。</li><li>公共溢出区域法    将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。</li></ol><h3 id="几种数组copy方法的速度差异"><a href="#几种数组copy方法的速度差异" class="headerlink" title="几种数组copy方法的速度差异"></a>几种数组copy方法的速度差异</h3><ol><li>for 循环逐一复制        for循环适合于小型数组</li><li>System.arraycopy()</li><li>Arrays.copyOf()        本质上调用的是System.arraycopy(）方法</li><li>使用clone()        Object类中的一个本地方法，这里虽然返回Object，看着需要强制类型转换，但Object子类重写了这个方法，会返回相应的类型。</li></ol><h3 id="ConcurrentHashMap-在-JDK-1-8-中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？"><a href="#ConcurrentHashMap-在-JDK-1-8-中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？" class="headerlink" title="ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？"></a>ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？</h3><ol><li>粒度降低了；</li><li>JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。</li><li>在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。            </li></ol>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础面试题</title>
      <link href="2020/10/01/Java%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>2020/10/01/Java%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="String-StringBuffer-StringBuilder"><a href="#String-StringBuffer-StringBuilder" class="headerlink" title="String StringBuffer StringBuilder"></a>String StringBuffer StringBuilder</h2><ol><li>运行速度快慢为：StringBuilder &gt; StringBuffer &gt; String </li><li>操作数量较少的字符串用String，不可修改的字符串；<br>在单线程且操作大量字符串用StringBuilder,速度快，但线程不安全，可修改；<br>在多线程且操作大量字符串用StringBuffer，线程安全，可修改。</li><li>for循环中追加字符串  IDEA会提示使用StringBuilder</li><li>扩容机制：StringBuffer/StringBuilder在没有传参的情况下默认初始容量是16；有参数的情况下，初始容量是16+字符串的长度，并且是用append（）方法追加的字符。ensureCapacityInternal（）int newCapacity = (value.length &lt;&lt; 1) + 2；增加为自身长度的一倍然后再加2；这个时候如果还是放不下，那就直接扩容到它需要的长度  newCapacity = minCapacity;</li></ol><h2 id="包装类-基本数据类型、-拆箱装箱、常量池缓存机制"><a href="#包装类-基本数据类型、-拆箱装箱、常量池缓存机制" class="headerlink" title="包装类 基本数据类型、 拆箱装箱、常量池缓存机制"></a>包装类 基本数据类型、 拆箱装箱、常量池缓存机制</h2><ol><li>包装类是对象，有自己的方法，默认值为null</li><li>存储位置不同，基本数据类型直接将值保存在值栈中，而包装类型是把对象放在堆中，然后通过对象的引用来调用</li><li>装箱就是将基本数据类型包装成包装类型，拆箱就是反过来将包装类型拆成基本数据类型。</li><li>装箱过程是通过调用包装类的valueOf方法实现的，而拆箱过程是通过调用包装器的 xxxValue方法实现的。（其中xxx代表对应的基本数据类型）</li><li>常量池的缓存机制：Double 和 Float 无 ；Boolean类型的比较类似单纯地比较他们的值是否相等。</li></ol><h2 id="如何理解java中只有值传递"><a href="#如何理解java中只有值传递" class="headerlink" title="如何理解java中只有值传递"></a>如何理解java中只有值传递</h2><ol><li>基本类型传递的是值的副本，引用类型传递的是引用的副本。</li><li>java中不管是值对象还是引用对象都是值传递，在其他方法里面改变引用类型的值肯定是通过引用改变的，当传递引用对象的时候传递的是复制过的对象句柄(引用)，注意这个引用是复制过的，也就是说又在内存中复制了一份句柄，这时候有两个句柄是指向同一个对象的，所以你改变这个句柄对应空间的数据会影响外部的变量的，虽然是复制的但是引用指向的是同一个地址，当你把这个句柄指向其他对象的引用时并不会改变原对象，因为你拿到的句柄是复制过的引用。<br>总结java中的句柄(引用)是复制过的，所以说java只有值传递。</li></ol><h2 id="十进制的数在内存中是怎么存的"><a href="#十进制的数在内存中是怎么存的" class="headerlink" title="十进制的数在内存中是怎么存的"></a>十进制的数在内存中是怎么存的</h2><p>  基于补码</p><h2 id="java8新特性"><a href="#java8新特性" class="headerlink" title="java8新特性"></a>java8新特性</h2><ol><li>Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 .sort()等</li><li>Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 例子：list.stream().filter().collect(Collectors.toList());</li><li>LocalDate和LocalTime类</li></ol><h2 id="和equals之间的区别"><a href="#和equals之间的区别" class="headerlink" title="==和equals之间的区别"></a>==和equals之间的区别</h2><ol><li>种类不同        ==：运算符        equals:是Object类里面的一个方法</li><li>作用不同       ==：既可以比较基本数据类型（比较数值） 又可以比较引用数据类型（比较地址）  equals:只能比较引用数据类型，表示如何制定一个类型的比较规则,可以按照自己的意愿修改比较规则   比如：String类型比较字符串的内容</li></ol><h2 id="为什么重写euqals-方法-必须重写-hashCode"><a href="#为什么重写euqals-方法-必须重写-hashCode" class="headerlink" title="为什么重写euqals 方法 必须重写 hashCode()"></a>为什么重写euqals 方法 必须重写 hashCode()</h2><ol><li>两个对象 hashCode() 所得hash值相等 ， 但equals()方法不一定返回true</li><li>两个对象 equals() 返回true，那么对象调用hashCode()返回的hash值一定相等</li><li>如果 仅重写 equals(),而不重写hashcode(),则存在 equals方法会返回true，而hashcode()方法返回的hash值不相等</li><li>为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的</li><li>lombok插件 @Data 自动重写 hashCode() equals() toString()方法</li></ol><h2 id="面向对象-特征、六原则一法则"><a href="#面向对象-特征、六原则一法则" class="headerlink" title="面向对象  特征、六原则一法则"></a>面向对象  特征、六原则一法则</h2><ol><li>面向对象的特征：封装 继承 多态 。封装：隐藏对象的属性和实现细节，仅对外提供公共访问方式，将变化隔离，便于使用，提高复用性和安全性。继承：提高代码复用性；继承是多态的前提。多态：父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。提高了程序的拓展性。</li><li>单一职责原则：一个类只做它该做的事情。”高内聚”</li><li>开闭原则：软件实体应当对扩展开放，对修改关闭。</li><li>依赖倒转原则：面向接口编程。（该原则说得直白和具体一些就是声明方法的参数类型、方法的返回类型、变量的引用类型时，尽可能使用抽象类型而不用具体类型，因为抽象类型可以被它的任何一个子类型所替代，请参考下面的里氏替换原则。）</li><li>里氏替换原则：任何时候都可以用子类型替换掉父类型。简单的说就是能用父类型的地方就一定能使用子类型。</li><li>接口隔离原则：接口要小而专，绝不能大而全。</li><li>聚合复用原则：优先使用聚合关系复用代码。</li><li>迪米特法则：迪米特法则又叫最少知识原则，一个对象应当对其他对象有尽可能少的了解。（迪米特法则简单的说就是如何做到”低耦合”，门面模式和调停者模式就是对迪米特法则的践行。)</li></ol><h2 id="Java泛型所给予的编译期检查"><a href="#Java泛型所给予的编译期检查" class="headerlink" title="Java泛型所给予的编译期检查"></a>Java泛型所给予的编译期检查</h2><p>Java泛型所给予的编译期检查，是根据该泛型对象的引用类型来定的，如果泛型类对象的引用类型的&lt; &gt;里有具体类型，那么就会执行相应的编译期检查。<br>在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。</p><h2 id="java是解释型语言还是编译型语言？"><a href="#java是解释型语言还是编译型语言？" class="headerlink" title="java是解释型语言还是编译型语言？"></a>java是解释型语言还是编译型语言？</h2><p>有人说Java是编译型的。因为所有的Java代码都是要编译的，.java不经过编译就无法执行。<br>也有人说Java是解释型的。因为java代码编译后不能直接运行，它是解释运行在JVM上的，所以它是解释型的。<br>对于C和C++，它们经过一次编译之后，可以由操作系统直接执行，所以它们是编译型语言。而Java不一样，它首先由编译器编译成.class（字节码）文件，然后在通过JVM从.class文件中读一行解释执行一行，所以它是解释型的语言。也正是由于java对于多种不同的操作系统有不同的JVM，所以实现了真正意义上的跨平台。</p><h2 id="finalize方法是Object提供的的实例方法，使用规则如下"><a href="#finalize方法是Object提供的的实例方法，使用规则如下" class="headerlink" title="finalize方法是Object提供的的实例方法，使用规则如下"></a>finalize方法是Object提供的的实例方法，使用规则如下</h2><ol><li>当对象不再被任何对象引用时，GC会调用该对象的finalize()方法</li><li>finalize()是Object的方法，子类可以覆盖这个方法来做一些系统资源的释放或者数据的清理</li><li>可以在finalize()让这个对象再次被引用，避免被GC回收；但是最常用的目的还是做cleanup</li><li>Java不保证这个finalize()一定被执行；但是保证调用finalize的线程没有持有任何user-visible同步锁。</li><li>在finalize里面抛出的异常会被忽略，同时方法终止。</li><li>当finalize被调用之后，JVM会再一次检测这个对象是否能被存活的线程访问得到，如果不是，则清除该对象。也就是finalize只能被调用一次；也就是说，覆盖了finalize方法的对象需要经过两个GC周期才能被清除。</li></ol><h2 id="深拷贝和浅拷贝有什么区别"><a href="#深拷贝和浅拷贝有什么区别" class="headerlink" title="深拷贝和浅拷贝有什么区别"></a>深拷贝和浅拷贝有什么区别</h2><ol><li>浅拷贝：复制基本类型的属性；引用类型的属性复制，复制栈中的变量 和 变量指向堆内存中的对象的指针，不复制堆内存中的对象。</li><li>深拷贝：复制基本类型的属性；引用类型的属性复制，复制栈中的变量 和 变量指向堆内存中的对象的指针和堆内存中的对象。</li><li>可以说一下BeanUtils.copyProperties()    Arrays.copyOf() clone()等</li></ol><h2 id="Class类的作用"><a href="#Class类的作用" class="headerlink" title="Class类的作用"></a>Class类的作用</h2><ol><li>Class类是一个比较特殊的类。特殊在这是一个在类加载过程中由虚拟机生成的，由于表示被加载类的类型信息的对象。简单地说，我们创建一个int变量，那么这个int变量是个整数类型，那么我们怎么知道这个类型是整数类型呢？就是通过这个Class类来知道的。java是面向对象编程的，java中几乎所有的数据都是对象，那么是对象，就必须知道自己到底是哪一种类型的对象。于是Class类便顺势而生了。</li><li>Class类的作用，本质上讲，就是前面所说的，它代表着一个类的类型信息。正是因为这个特殊作用的存在，Class类能够实现它所代表的这个类的所有功能，包括创建这个类的实例，获得所有的构造函数，方法，字段值等等，可以说无所不能。</li></ol><h2 id="什么是反射机制，有什么作用"><a href="#什么是反射机制，有什么作用" class="headerlink" title="什么是反射机制，有什么作用"></a>什么是反射机制，有什么作用</h2><ol><li>在Java环境中，反射机制允许程序在执行时获取某个类自身的定义信息，也可以实现动态创建类的对象、变更属性的内容或执行特定的方法的功能。从而使Java具有动态语言的特性，增强了程序的灵活性和可移植性。</li><li>Java反射机制主要用于实现以下功能。1.在运行时判断任意一个对象所属的类型。2.在运行时构造任意一个类的对象。3.在运行时判断任意一个类所具有的成员变量和方法。4.在运行时调用任意一个对象的方法，甚至可以调用private方法。</li><li>实现Java反射机制的API在Java.lang.reflect包下，具有以下几点。1. Class类：代表一个类。2. Filed类：代表类的成员变量。3.Method类：代表类的方法。4.Constructor类：代表类的构造方法。5.Array类：提供了动态创建数组及访问数组元素的静态方法。该类中的所有方法都是静态的。</li><li>Spring通过反射创建对象，并将对象放到spring ioc容器中；Spring的拦截器也是基于反射实现的；</li></ol><h2 id="Synchronized-lock-volatile"><a href="#Synchronized-lock-volatile" class="headerlink" title="Synchronized lock volatile"></a>Synchronized lock volatile</h2><p>synchronized修饰静态方法以及同步代码块   synchronized (类.class)用法锁的是类，线程想要执行对应同步代码，需要获得类锁。<br>synchronized修饰成员方法，线程获取的是当前调用该方法的对象实例的对象锁。</p><h2 id="synchronized关键字和volatile关键字比较"><a href="#synchronized关键字和volatile关键字比较" class="headerlink" title="synchronized关键字和volatile关键字比较"></a>synchronized关键字和volatile关键字比较</h2><p>volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。<br>但是volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块。<br>synchronized关键字在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。</p><p>多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞。<br>volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。<br>volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。</p><h2 id="既然有了字节流，为什么还要有字符流"><a href="#既然有了字节流，为什么还要有字符流" class="headerlink" title="既然有了字节流，为什么还要有字符流"></a>既然有了字节流，为什么还要有字符流</h2><p>字符流是由JVM将字节转换得到的，所以这个过程还是非常耗时的，字节流在处理时是逐个字节读取，在读取汉字时会出现乱码问题。<br>图片和音频这些文件用字节流比较好，涉及到字符的使用字符流比较好。</p>]]></content>
      
      
      <categories>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
